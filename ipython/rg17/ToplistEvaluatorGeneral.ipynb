{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from rg17 import evaluate_toplist as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../pipelines/TrendApproximation.json\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_name_with_account_file_path = ph.get(\"player_name_with_accounts_file_path\")\n",
    "schedule_file_path = ph.get(\"schedule_file_path\")\n",
    "w2v_model_dir = ph.get(\"w2v_root_folder\")\n",
    "experiment_id = ph.get(\"experiment_id\")\n",
    "TIME_HOUR_VALS = ph.get(\"time_hour_vals\")\n",
    "RELEVANCE_TYPE = ph.get(\"relevance_type\")\n",
    "RELEVANCE_SUBSET = \"positive\" #ph.get(\"relevance_subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Player Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(player_name_with_account_file_path) as f:\n",
    "    player_account_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for finals\n",
    "player_account_map[\"Stan Wawrinka\"] = [\"stanwawrinka\"]\n",
    "player_account_map[\"Novak Djokovic\"] = [\"DjokerNole\"]\n",
    "player_account_map[\"Caroline Garcia\"] = [\"CaroGarcia\"]\n",
    "player_account_map[\"Caroline Wozniacki\"] = [\"CaroWozniacki\"]\n",
    "player_account_map[\"Marin Cilic\"] = [\"cilic_marin\"]\n",
    "player_account_map[\"Kristina Mladenovic\"] = [\"KikiMladenovic\"]\n",
    "player_account_map[\"Dominic Thiem\"] = [\"ThiemDomi\"]\n",
    "player_account_map[\"Rafael Nadal\"] = [\"RafaelNadal\"]\n",
    "player_account_map[\"Timea Bacsinszky\"] = [\"TimeaOfficial\"]\n",
    "player_account_map[\"Pablo Carreno Busta\"] = [\"pablocarreno91\"]\n",
    "player_account_map[\"Simona Halep\"] = [\"Simona_Halep\"]\n",
    "player_account_map[\"Andy Murray\"] = [\"andy_murray\"]\n",
    "# for others\n",
    "player_account_map[\"Tommy Robredo\"] = ['TRobredo']\n",
    "player_account_map[\"Sebastien Grosjean\"] = ['sebboca29']\n",
    "player_account_map[\"Mona Barthel\"] = ['BarthelMona']\n",
    "player_account_map[\"Arnaud Clement\"] = ['arnaudclement']\n",
    "player_account_map[\"Anett Kontaveit\"] = ['Vamosanett']#'@AnettKontaveit'\n",
    "player_account_map[\"David Goffin\"] = ['David__Goffin']\n",
    "player_account_map[\"Audrey Albie\"] = ['DreyAlbie']\n",
    "player_account_map[\"Jo-Wilfried Tsonga\"] = ['tsonga7']\n",
    "\n",
    "### TODO: include in player matches .json files!!!\n",
    "player_account_map[\"Ernests Gulbis\"] = [\"egulbisfans\"]#['@ernestgulbis', '@ErnestsGulbisFC']\n",
    "\n",
    "player_account_map[\"Petra Martic\"] = ['PetraMartic1991']\n",
    "player_account_map[\"Venus Williams\"] = ['Venuseswilliams']\n",
    "player_account_map[\"Marion Bartoli\"] = ['bartoli_marion']\n",
    "player_account_map[\"Francesca Schiavone\"] = ['Schiavone_Fra']\n",
    "player_account_map[\"Garbi\u00f1e Muguruza\"] = ['GarbiMuguruza']\n",
    "player_account_map[\"Fabio Fognini\"] = ['fabiofogna']\n",
    "player_account_map[\"Elise Mertens\"] = ['elise_mertens']\n",
    "player_account_map[\"Borna Coric\"] = ['borna_coric']\n",
    "player_account_map[\"Camila Giorgi\"] = ['CamilaGiorgi_it']\n",
    "player_account_map[\"Nikoloz Basilashvili\"] = ['NikaBasil']\n",
    "\n",
    "### TODO: include in player matches .json files!!!\n",
    "player_account_map[\"Alexander Zverev\"] = [\"FanZverev\"] #['@saschazverev123', '@AlexZverev123', '@zverevtennis']\n",
    "\n",
    "player_account_map[\"Dustin Brown\"] = ['DreddyTennis']\n",
    "\n",
    "### TODO: include in player matches .json files!!!\n",
    "player_account_map[\"Donald Young\"] = ['Yimlife1313'] #['@DonaldYoungUSA', '@DonaldYoungATP', '@DonaldYoung']\n",
    "\n",
    "player_account_map[\"Martina Hingis\"] = ['mhingis']\n",
    "\n",
    "# there is no account ???\n",
    "player_account_map[\"Andrey Kuznetsov\"] = []#['@AKandreyln', '@AndreyKuznetsov']\n",
    "\n",
    "player_account_map[\"Frances Tiafoe\"] = ['FTiafoe']\n",
    "player_account_map[\"Gael Monfils\"] = ['Gael_Monfils']#, '@gmonfils']\n",
    "\n",
    "# there is no account ???\n",
    "player_account_map[\"Bernard Tomic\"] = []#['@BTomicOfficial', '@BernardTomicAU', '@BernardTomicFC']\n",
    "\n",
    "player_account_map[\"Benoit Paire\"] = ['benoitpaire']\n",
    "player_account_map[\"Angelique Kerber\"] = ['AngeliqueKerber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df = pd.read_csv(schedule_file_path, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_categories = [\"boy\", \"girl\", \"wheelchair\", \"legends over 45\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert start dates to UTC for the proper evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"startDate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utc_hour_map = {\n",
    "    \"11:00 AM\" : 9,\n",
    "    \"10:00 AM\" : 8,\n",
    "    \"12:00 PM\" : 10,\n",
    "    \"2:00 PM\" : 12,\n",
    "    \"11:30 AM\" : 10, # hour was rounded up\n",
    "    \"3:00 PM\" : 13,\n",
    "    \"12:45 PM\" : 11 # hour was rounded up\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"] = schedule_df[\"startDate\"].apply(lambda x: utc_hour_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Schedule\n",
    "\n",
    "   * only Single matches are kept\n",
    "   * only important categories are kept (Men's, Women's, Legends under 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_categories(match_cat, excluded_cats=excluded_categories):\n",
    "    match_cat_lower = match_cat.lower()\n",
    "    keep_this = True\n",
    "    for cat in excluded_cats:\n",
    "        if cat in match_cat_lower:\n",
    "            keep_this = False\n",
    "            break\n",
    "    return keep_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_df = schedule_df[schedule_df[\"matchHeader\"].apply(filter_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches_df = matches_df[matches_df[\"date\"] > \"2017-05-27\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = matches_df[\"date\"].unique()\n",
    "daily_tennis_players = {}\n",
    "for d in dates:\n",
    "    daily_df = matches_df[matches_df[\"date\"] == d]\n",
    "    daily_players = list(set(daily_df[\"playerName active\"]).union(set(daily_df[\"playerName opponent\"])))\n",
    "    daily_tennis_players[d] = daily_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(matches_df), len(matches_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player name parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players = list(set(matches_df[\"playerName active\"]).union(matches_df[\"playerName opponent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "player_info_map = {}\n",
    "players_without_account = []\n",
    "for player in players:\n",
    "    player_info_map[player] = {}\n",
    "    player_info_map[player][\"name_parts\"] = [p.lower() for p in re.compile(\"[\\s,-]+\").split(player)]\n",
    "    if player in player_account_map:\n",
    "        player_info_map[player][\"accounts\"] = [\"@\" + et.transform_account_name(a, remove_digits=False, remove_under_score=False, to_lower=False) for a in player_account_map[player]]\n",
    "    else:\n",
    "        player_info_map[player][\"accounts\"] = None\n",
    "        players_without_account.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(players_without_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Should we exclude player accounts from evaluation now???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for key in player_info_map:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map[\"Garbi\u00f1e Muguruza\"][\"name_parts\"] = ['garbine', 'muguruza']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show multi-account players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the pre-filtering there is no duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for player, info in player_info_map.items():\n",
    "    if info[\"accounts\"] != None and len(info[\"accounts\"]) > 1:\n",
    "        print('player_account_map[\"%s\"] =' % player, info[\"accounts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant players per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2relevance(values, relevance):\n",
    "    return dict(zip(values, relevance * np.ones(len(values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words = [\"play\",\"match\"]\n",
    "time_hour_vals = ph.get('time_hour_vals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevant_arr = []\n",
    "for d in dates:\n",
    "    daily_player_names, daily_player_accounts = [], []\n",
    "    for p in daily_tennis_players[d]:\n",
    "        daily_player_names += player_info_map[p][\"name_parts\"]\n",
    "        if player_info_map[p][\"accounts\"] != None:\n",
    "            daily_player_accounts += player_info_map[p][\"accounts\"]\n",
    "    daily_player_names_map = list2relevance(daily_player_names, 1)\n",
    "    daily_player_accounts_map = list2relevance(daily_player_accounts, 1)\n",
    "    for kw in key_words:\n",
    "        for h in time_hour_vals:\n",
    "            relevant_arr.append([d, \"%.2i:00\" % h, kw, daily_player_names_map, daily_player_accounts_map])\n",
    "relevant_df = pd.DataFrame(relevant_arr, columns=[\"date\", \"time\", \"key_word\", \"names_parts\", \"accounts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pd.read_csv(\"/mnt/idms/fberes/network/combined_occ/occ_scores/%s_with_scores.csv\" % experiment_id, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "et.get_toplist(pair_occs_df, [\"play\"], [\"2017-06-06T13:00\"], score_col=\"rel_count_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_set = set(pair_occs_df[\"word_2\"].unique())\n",
    "word_1_set = set(pair_occs_df[\"word_1\"].unique())\n",
    "len(word_1_set), len(word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_missing_words(info_key, word_set):\n",
    "    num_missing = 0\n",
    "    for player, info in player_info_map.items():\n",
    "        diff = list(set(info[info_key]).difference(word_set))\n",
    "        if len(diff) != 0:\n",
    "            num_missing += 1\n",
    "            print(\"%s: %s missing!\" % (player, diff))\n",
    "    print(num_missing)\n",
    "            \n",
    "def set_matching_words(info_key, word_set):\n",
    "    num_missing = 0\n",
    "    for player, info in player_info_map.items():\n",
    "        match = list(set(info[info_key]).intersection(word_set))\n",
    "        player_info_map[player][info_key] = match\n",
    "        if len(match) == 0:\n",
    "            num_missing += 1\n",
    "    print(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Checking names (All names are present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formerly\n",
    "\n",
    "   * 160 player is missing some words\n",
    "   * Most of them missing only first name! Because name parts were not included in top important words!!!\n",
    "   * Only 72 player has no name part mentioned.\n",
    "   \n",
    "### Updated\n",
    "\n",
    "   * 67 player missing some words\n",
    "   * 17 player has no name part mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map[\"Katerina Siniakova\"][\"accounts\"] = [\"@SiniakovaSquad\"] # \"Siniakova\" is in rg17_tweets_eng.csv AND eng_stemmed !!!\n",
    "player_info_map[\"Matwe Middelkoop\"][\"accounts\"] = [\"@Mside83\"] # !!! \n",
    "player_info_map[\"Edouard Roger-Vasselin\"][\"accounts\"] = [\"@ERogerVasselin\"] # 'edouard' not found BUT 'Edouard' is present!!! WHY???\n",
    "# Nikola Mektic 'mektic' word is in the data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_matching_words(\"name_parts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_toplist(pair_occs_df, [\"match\"], [\"2017-06-01T07:00\"], score_col=\"snapshot_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experimental Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pair_occs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_2 frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_cols = [\"global_val\",\"snapshot_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_2_stats = pair_occs_df.groupby(by=[\"word_2\"])[stat_cols].mean()\n",
    "word_2_counts = pair_occs_df.groupby(by=[\"word_2\"])[\"date\"].count()\n",
    "word_2_counts_norm = word_2_counts / word_2_counts.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_factor = np.floor(np.log(word_2_counts / 5) / np.log(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"frequency_val\"] = pair_occs_df[\"word_2\"].apply(lambda x: 0.0 if freq_factor[x] < 1 else 1.0 / freq_factor[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate normalization coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_weight = ph.get(\"snapshot_weight\")\n",
    "frequency_weight = ph.get(\"frequency_weight\")\n",
    "print(snapshot_weight, frequency_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"r\"] = (1.0 - (snapshot_weight + frequency_weight)) * pair_occs_df[\"global_val\"] + snapshot_weight * pair_occs_df[\"snapshot_val\"] + frequency_weight * pair_occs_df[\"frequency_val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) rel_count_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_vals = ph.get(\"score_c_vals\")\n",
    "print(score_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rel_count_calculator(row, c=0.0, ):\n",
    "    num = row[\"word_2_count\"] + row[\"r\"] * c\n",
    "    denom = row[\"word_1_count\"] + c\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in score_vals:\n",
    "    pair_occs_df[\"rel_count_c%i\" % c] = pair_occs_df.apply(lambda x: rel_count_calculator(x, c=c), axis=1)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"rel_count_c5\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) norm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in score_vals:\n",
    "    pair_occs_df[\"norm_c%i\" % c] = pair_occs_df[\"rel_count_c%i\" % c] / pair_occs_df[\"r\"]\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"norm_c5\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_models = et.load_w2v_models(\"%s/dim_%i/\" % (w2v_model_dir, ph.get(\"w2v_model_dim\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Jaccard and Cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_root_folder = ph.get(\"distance_root_folder\")\n",
    "jaccard_distances = et.load_distance_model(\"%s/jaccard.dist\" % distance_root_folder)\n",
    "cosine_distances = et.load_distance_model(\"%s/cosine.dist\" % distance_root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ndcg_for_relevant_record(rel_rec, rel_cols, score_col, exclude_player_words=True, top_k=None, general_words=None, verbose=False):\n",
    "    \"\"\"'general_words' must be a relevance dictionary.\"\"\"\n",
    "    time_id, key_word = rel_rec[\"time\"], rel_rec[\"key_word\"]\n",
    "    snapshot_id = \"%sT%s\" % (rel_rec[\"date\"], time_id)\n",
    "    # define relevant words\n",
    "    relevant_words = dict()\n",
    "    for rc in rel_cols:\n",
    "        relevant_words.update(rel_rec[rc])\n",
    "    if general_words != None:\n",
    "        relevant_words.update(general_words)\n",
    "    # define words to be excluded from the toplist    \n",
    "    if exclude_player_words and \"key_exclude_words\" in rel_rec:\n",
    "        to_be_excluded = rel_rec[\"key_exclude_words\"]\n",
    "    else:\n",
    "        to_be_excluded = None\n",
    "    # get toplist\n",
    "    if score_col == \"word_2_vec\":\n",
    "        pred_words = list(et.get_w2v_toplist(w2v_models, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded)[\"word_2\"])\n",
    "    elif score_col == \"jaccard\":\n",
    "        pred_words = list(et.get_distance_toplist(jaccard_distances, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded )[\"word_2\"])\n",
    "    elif score_col == \"cosine\":\n",
    "        pred_words = list(et.get_distance_toplist(cosine_distances, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded )[\"word_2\"])\n",
    "    else:\n",
    "        pred_words = list(et.get_toplist(pair_occs_df, [key_word], [snapshot_id], score_col=score_col, excluded_words=to_be_excluded)[\"word_2\"])\n",
    "    if verbose:\n",
    "        print(pred_words)\n",
    "        print(relevant_words)\n",
    "    ndcg_score = et.ndcg(relevant_words, pred_words, k=top_k)\n",
    "    return (snapshot_id, rel_rec[\"date\"], time_id, score_col, key_word, ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing, functools\n",
    "\n",
    "def get_ndcg_single_thread(top_k, row, rel_cols, general_words, score_col):\n",
    "    return get_ndcg_for_relevant_record(row, rel_cols, score_col, top_k=top_k, general_words=general_words)\n",
    "\n",
    "def get_ndcg_from_threads(top_k, rel_cols, relevant_df, time_ids, score_cols, general_words, n_threads=1):\n",
    "    print(len(relevant_df))\n",
    "    filtered_relevant_df = relevant_df[relevant_df[\"time\"].isin(time_ids)]\n",
    "    print(len(filtered_relevant_df))\n",
    "    ndcg_info_list = []\n",
    "    if n_threads > 1:\n",
    "        print(\"Calculating NDCG on %i threads\" % n_threads)\n",
    "    for idx, row in filtered_relevant_df.iterrows():\n",
    "        if n_threads == 1:\n",
    "            for score_col in score_cols:\n",
    "                ndcg_info_list += [get_ndcg_single_thread(top_k, row, rel_cols, general_words, score_col)]\n",
    "        else:\n",
    "            f_partial = functools.partial(get_ndcg_single_thread, top_k, row, rel_cols, general_words)\n",
    "            pool = multiprocessing.Pool(processes=n_threads)\n",
    "            res = pool.map(f_partial, score_cols)\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            ndcg_info_list += res\n",
    "    ndcg_df = pd.DataFrame(ndcg_info_list, columns=[\"snapshot_id\",\"date\",\"time\",\"score_id\",\"key_word\",\"ndcg\"])\n",
    "    return ndcg_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting general words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COMMON_WORD_RELEVANCE = -1.0\n",
    "general_words = {}\n",
    "\n",
    "if RELEVANCE_SUBSET == \"discriminative\":\n",
    "    general_words.update({\n",
    "        \"rg17\":COMMON_WORD_RELEVANCE,\n",
    "        \"rg2017\":COMMON_WORD_RELEVANCE,\n",
    "        \"rolandgarros\":COMMON_WORD_RELEVANCE,\n",
    "        \"roland\":COMMON_WORD_RELEVANCE,\n",
    "        \"garros\":COMMON_WORD_RELEVANCE,\n",
    "        \"rolandgarros2017\":COMMON_WORD_RELEVANCE,\n",
    "        \"frenchopen\":COMMON_WORD_RELEVANCE,\n",
    "        \"french\":COMMON_WORD_RELEVANCE,\n",
    "        \"open\":COMMON_WORD_RELEVANCE,\n",
    "        \"clay\":COMMON_WORD_RELEVANCE,\n",
    "        \"slam\":COMMON_WORD_RELEVANCE,\n",
    "        \"set\":COMMON_WORD_RELEVANCE,\n",
    "        \"round\":COMMON_WORD_RELEVANCE      \n",
    "    })\n",
    "print(general_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cols = [\"word_2_vec\", \"jaccard\", \"cosine\"]\n",
    "#score_cols += [\"rel_count_c%i_plus_ray\" % i for i in [0,1,2,5,10]]\n",
    "#score_cols += [\"norm_c%i_plus_ray\" % i for i in [0,1,2,5,10]]\n",
    "score_cols += [\"rel_count_c%i\" % i for i in score_vals]\n",
    "score_cols += [\"norm_c%i\" % i for i in score_vals]\n",
    "print(score_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting time of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time_ids = [\"%.2i:00\" % t for t in TIME_HOUR_VALS]\n",
    "time_ids = [\"%.2i:00\" % t for t in [4,7,10,13,16,19]]\n",
    "time_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDCG in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ndcg_df = get_ndcg_from_threads(100, [\"names_parts\",\"accounts\"], relevant_df, time_ids, score_cols, general_words, n_threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ndcg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndcg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean NDCG performance for score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndcg_df.groupby(by=\"score_id\")[\"ndcg\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndcg_for_plots = ndcg_df[ndcg_df[\"score_id\"].isin([\"word_2_vec\",\"cosine\",\"jaccard\",\"rel_count_c5\",\"norm_c5\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paper_rc = {'lines.linewidth': 5,'lines.markersize': 20}              \n",
    "sns.set_context(\"paper\", rc = paper_rc, font_scale = 4.25)\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#sns.set(font=\"DejaVu Sans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) Compare co-occurence scores for date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(data=ndcg_for_plots, x=\"date\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.)  Compare co-occurence scores for time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=ndcg_for_plots, x=\"time\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii.) Difference between players keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_player_perf(key_words):\n",
    "    score_filtered = ndcg_for_plots[ndcg_for_plots[\"key_word\"].isin(key_words)]\n",
    "    score_filtered = score_filtered[score_filtered[\"score_id\"] == \"norm_c5\"]\n",
    "    #score_filtered = score_filtered[score_filtered[\"date\"].isin([\"2017-06-08\",\"2017-06-09\",\"2017-06-10\",\"2017-06-11\"])]\n",
    "    score_filtered = score_filtered[score_filtered[\"date\"].isin([\"2017-05-28\",\"2017-05-29\",\"2017-05-30\",\"2017-05-31\",\"2017-06-01\",\"2017-06-02\",\"2017-06-03\"])]\n",
    "    g = sns.factorplot(data=score_filtered, x=\"snapshot_id\", y=\"ndcg\", hue=\"key_word\", size=10, aspect=3)\n",
    "    g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_player_perf([\"match\",\"play\"])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}