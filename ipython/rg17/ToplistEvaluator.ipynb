{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from rg17 import evaluate_toplist as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../pipelines/TrendApproximation.json\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_name_with_account_file_path = ph.get(\"player_name_with_accounts_file_path\")\n",
    "schedule_file_path = ph.get(\"schedule_file_path\")\n",
    "w2v_model_dir = ph.get(\"w2v_root_folder\")\n",
    "experiment_id = ph.get(\"experiment_id\")\n",
    "TIME_HOUR_VALS = ph.get(\"time_hour_vals\")\n",
    "RELEVANCE_TYPE = ph.get(\"relevance_type\")\n",
    "RELEVANCE_SUBSET = ph.get(\"relevance_subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Player Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(player_name_with_account_file_path) as f:\n",
    "    player_account_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_account_map[\"Stan Wawrinka\"] = [\"stanwawrinka\"]\n",
    "player_account_map[\"Novak Djokovic\"] = [\"DjokerNole\"]\n",
    "player_account_map[\"Caroline Garcia\"] = [\"CaroGarcia\"]\n",
    "player_account_map[\"Caroline Wozniacki\"] = [\"CaroWozniacki\"]\n",
    "player_account_map[\"Marin Cilic\"] = [\"cilic_marin\"]\n",
    "player_account_map[\"Kristina Mladenovic\"] = [\"KikiMladenovic\"]\n",
    "player_account_map[\"Dominic Thiem\"] = [\"ThiemDomi\"]\n",
    "player_account_map[\"Rafael Nadal\"] = [\"RafaelNadal\"]\n",
    "player_account_map[\"Timea Bacsinszky\"] = [\"TimeaOfficial\"]\n",
    "player_account_map[\"Pablo Carreno Busta\"] = [\"pablocarreno91\"]\n",
    "player_account_map[\"Simona Halep\"] = [\"Simona_Halep\"]\n",
    "player_account_map[\"Andy Murray\"] = [\"andy_murray\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df = pd.read_csv(schedule_file_path, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_categories = [\"boy\", \"girl\", \"wheelchair\", \"legends over 45\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert start dates to UTC for the proper evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"startDate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utc_hour_map = {\n",
    "    \"11:00 AM\" : 9,\n",
    "    \"10:00 AM\" : 8,\n",
    "    \"12:00 PM\" : 10,\n",
    "    \"2:00 PM\" : 12,\n",
    "    \"11:30 AM\" : 10, # hour was rounded up\n",
    "    \"3:00 PM\" : 13,\n",
    "    \"12:45 PM\" : 11 # hour was rounded up\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"] = schedule_df[\"startDate\"].apply(lambda x: utc_hour_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Schedule\n",
    "\n",
    "   * only Single matches are kept\n",
    "   * only important categories are kept (Men's, Women's, Legends under 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_categories(match_cat, excluded_cats=excluded_categories):\n",
    "    match_cat_lower = match_cat.lower()\n",
    "    keep_this = True\n",
    "    for cat in excluded_cats:\n",
    "        if cat in match_cat_lower:\n",
    "            keep_this = False\n",
    "            break\n",
    "    if not (\"final\" in match_cat_lower and \"single\" in match_cat_lower):\n",
    "        keep_this = False\n",
    "    return keep_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df = schedule_df[schedule_df[\"matchHeader\"].apply(filter_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(schedule_df), len(finals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single finals\n",
    "\n",
    "   * **canceled** matches are not excluded because people may talk about this events as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player name parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players = list(set(finals_df[\"playerName active\"]).union(finals_df[\"playerName opponent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map = {}\n",
    "for player in players:\n",
    "    player_info_map[player] = {\n",
    "        \"name_parts\": [p.lower() for p in player.split()],\n",
    "        \"accounts\": [\"@\" + et.transform_account_name(a, remove_digits=False, remove_under_score=False, to_lower=False) for a in player_account_map[player]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show multi-account players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for player, info in player_info_map.items():\n",
    "    if len(info[\"accounts\"]) > 1:\n",
    "        print(player, info[\"accounts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pd.read_csv(\"/mnt/idms/fberes/network/combined_occ/occ_scores/%s_with_scores.csv\" % experiment_id, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting string to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"global_val\"] = pair_occs_df[\"global_val\"].apply(eval)\n",
    "pair_occs_df[\"snapshot_val\"] = pair_occs_df[\"snapshot_val\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_set = set(pair_occs_df[\"word_2\"].unique())\n",
    "word_1_set = set(pair_occs_df[\"word_1\"].unique())\n",
    "len(word_1_set), len(word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_missing_words(info_key, word_set):\n",
    "    for player, info in player_info_map.items():\n",
    "        diff = list(set(info[info_key]).difference(word_set))\n",
    "        if len(diff) != 0:\n",
    "            print(\"%s: %s missing!\" % (player, diff))\n",
    "            \n",
    "def show_matching_words(info_key, word_set):\n",
    "    for player, info in player_info_map.items():\n",
    "        match = list(set(info[info_key]).intersection(word_set))\n",
    "        print(\"%s: %s\" % (player, match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Checking names (All names are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_matching_words(\"name_parts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Checking account names (All main account are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"accounts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"accounts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_matching_words(\"accounts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant player words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df[finals_df[\"matchScore\"] == \"Cancelled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2relevance(values, relevance):\n",
    "    return dict(zip(values, relevance * np.ones(len(values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: add players who play at the same time but not with our player - with negative relevance!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Other relevant events\n",
    "\n",
    "   * birthday for nadal\n",
    "   * injuries for other players?\n",
    "   * wheather? rain? etc???\n",
    "   * cancelled match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RELEVANCE_TYPE == \"binary\":\n",
    "    OPPONENT_RELEVANCE = 1.0\n",
    "    WINNER_INFO_RELEVANCE = 1.0\n",
    "    MATCH_INFO_RELEVANCE = 1.0\n",
    "    COMMON_WORD_RELEVANCE = -1.0    \n",
    "else:\n",
    "    OPPONENT_RELEVANCE = 5.0\n",
    "    WINNER_INFO_RELEVANCE = 4.0\n",
    "    MATCH_INFO_RELEVANCE = 3.0\n",
    "    COMMON_WORD_RELEVANCE = -5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winner Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winner_synonyms = [\"win\",\"won\",\"victori\",\"triumph\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loser Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loser_synonyms = [\"lose\", \"lost\", \"beaten\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_relevance_record(relevance_subset, date, time, utc_hour, winner, loser, score):\n",
    "    if score == \"Cancelled\":\n",
    "        to_iterate_on = [(winner, loser, None),(loser, winner, None)]\n",
    "    else:\n",
    "        to_iterate_on = [(winner, loser, 1),(loser, winner, 0)]\n",
    "    res = []\n",
    "    for p1, p2, is_winner in to_iterate_on:\n",
    "        n1, n2 = player_info_map[p1][\"name_parts\"], player_info_map[p2][\"name_parts\"]\n",
    "        acc1, acc2 = player_info_map[p1][\"accounts\"], player_info_map[p2][\"accounts\"]\n",
    "        for w in n1+acc1:\n",
    "            key_exclude = n1+acc1\n",
    "            key_exclude.remove(w)\n",
    "            player_relevant = dict()\n",
    "            # set relevance for winner information (only after the match started)\n",
    "            if time > utc_hour:\n",
    "                # in case of \"Cancelled\" there is only zero relevance\n",
    "                if is_winner == 1:\n",
    "                    player_relevant.update(list2relevance(winner_synonyms, WINNER_INFO_RELEVANCE))\n",
    "                    if relevance_subset != \"positive\":\n",
    "                        player_relevant.update(list2relevance(loser_synonyms, -WINNER_INFO_RELEVANCE))\n",
    "                elif is_winner == 0:\n",
    "                    if relevance_subset != \"positive\":\n",
    "                        player_relevant.update(list2relevance(winner_synonyms, -WINNER_INFO_RELEVANCE))\n",
    "                    player_relevant.update(list2relevance(loser_synonyms, WINNER_INFO_RELEVANCE))\n",
    "            # set relevance for final categories\n",
    "            if date in [\"2017-06-06\",\"2017-06-07\"]:\n",
    "                player_relevant.update(list2relevance([\"quarters\",\"quarter\",\"final\"], MATCH_INFO_RELEVANCE))\n",
    "            elif date in [\"2017-06-08\",\"2017-06-09\"]:\n",
    "                player_relevant.update(list2relevance([\"semi\",\"final\"], MATCH_INFO_RELEVANCE))\n",
    "            elif date in [\"2017-06-10\",\"2017-06-11\"]:\n",
    "                player_relevant.update(list2relevance([\"final\"], MATCH_INFO_RELEVANCE))\n",
    "            # set relevance for opponent information\n",
    "            opponent_relevant = list2relevance(n2+acc2, OPPONENT_RELEVANCE)\n",
    "            res.append([date, \"%.2i:00\" % time, p1, is_winner, w, key_exclude, player_relevant,  p2, opponent_relevant])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_infos = []\n",
    "for idx, row in finals_df.iterrows():\n",
    "    date, utc_hour, winner, loser, score = row[\"date\"], row[\"utc_start_hour\"], row[\"playerName active\"], row[\"playerName opponent\"], row[\"matchScore\"]\n",
    "    for time in TIME_HOUR_VALS:\n",
    "        relevant_infos += get_relevance_record(RELEVANCE_SUBSET, date, time, utc_hour, winner, loser, score)\n",
    "relevant_df = pd.DataFrame(relevant_infos, columns=[\"date\",\"time\",\"player\",\"is_winner\",\"key_word\", \"key_exclude_words\", \"key_relevant_words\", \"opponent\",\"opp_relevant_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(relevant_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving daily keywors to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggr_keyword_by_day = relevant_df.groupby(by=\"date\")[\"key_word\"].aggregate(lambda x: set(x))\n",
    "aggr_keyword_by_day.to_csv(ph.get(\"keywords_for_eval_path\"), sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: wawrinka loser information has relevance only in snapshots after match start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df[relevant_df[\"date\"]==\"2017-06-11\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pair_occs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_vals = [0,1,2,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for val in score_vals:\n",
    "    pair_occs_df[\"global_val_%i\" % val] = pair_occs_df[\"global_val\"].apply(lambda x: x[\"rel_count_%i\" % val] if x != 0 else 0.0)\n",
    "    pair_occs_df[\"snapshot_val_%i\" % val] = pair_occs_df[\"snapshot_val\"].apply(lambda x: x[\"rel_count_%i\" % val] if x != 0 else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplots(len(score_vals), 3, figsize=(20,20))\n",
    "for i, val in enumerate(score_vals):\n",
    "    print(i, val)\n",
    "    plt.subplot(len(score_vals),3,i*3+1)\n",
    "    pair_occs_df[\"rel_count_%i\" % val].hist(bins=50)\n",
    "    plt.subplot(len(score_vals),3,i*3+2)\n",
    "    pair_occs_df[\"global_val_%i\" % val].hist(bins=50)\n",
    "    plt.subplot(len(score_vals),3,i*3+3)\n",
    "    pair_occs_df[\"snapshot_val_%i\" % val].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average values for word_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat_cols = ['rel_count_0', 'rel_count_1', 'rel_count_2', 'rel_count_5', 'rel_count_10',\n",
    "    'global_val_0', 'snapshot_val_0', 'global_val_1', 'snapshot_val_1', 'global_val_2', 'snapshot_val_2', \n",
    "    'global_val_5', 'snapshot_val_5', 'global_val_10', 'snapshot_val_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_stats = pair_occs_df.groupby(by=[\"word_2\"])[stat_cols].mean()\n",
    "word_2_counts = pair_occs_df.groupby(by=[\"word_2\"])[\"date\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts.sort_values().tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def get_trace(name, words, const, color, size):\n",
    "    x_arr = [word_2_stats.ix[w][\"global_val_%i\" % const] for w in words]\n",
    "    #y_arr = [word_2_stats.ix[w][\"snapshot_val_%i\" % const] for w in words]\n",
    "    y_arr = [word_2_counts[w] for w in words]\n",
    "    z_arr = [word_2_stats.ix[w][\"rel_count_%i\" % const] for w in words]\n",
    "    trace = go.Scatter(\n",
    "        x = x_arr,\n",
    "        y = y_arr,\n",
    "        #z = z_arr,\n",
    "        name = name,\n",
    "        mode = 'markers',\n",
    "        text = words,\n",
    "        marker = dict(\n",
    "            size = size,\n",
    "            color = color,\n",
    "            line = dict(width = 2)\n",
    "        )\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def get_layout(const):\n",
    "    layout = go.Layout(\n",
    "        title='Word statitics (c=%i)' % const,\n",
    "        xaxis=dict(\n",
    "            title='global_val_%i' % const,\n",
    "            titlefont=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=18,\n",
    "                color='#7f7f7f'\n",
    "            )\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='#occurrences with other words (count)',\n",
    "            titlefont=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=18,\n",
    "                color='#7f7f7f'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_words = [\"game\",\"play\",\"match\",\"quarters\",\"quarter\",\"final\"] + winner_synonyms + loser_synonyms\n",
    "neg_words = [\"rolandgarros\",\"frenchopen\",\"clay\",\"slam\",\"set\"]\n",
    "player_words = list(relevant_df[\"key_word\"])\n",
    "\n",
    "figs_eval = []\n",
    "for const in score_vals:\n",
    "    data = [\n",
    "        get_trace(\"players\", player_words, const, \"blue\", 5),\n",
    "        get_trace(\"positive relevance\", pos_words, const, \"green\", 10),\n",
    "        get_trace(\"negative relevance\", neg_words, const, \"red\", 10)\n",
    "    ]\n",
    "    figs_eval.append(go.Figure(data=data, layout=get_layout(const)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_eval[0], filename='eval_word_stats_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_eval[1], filename='eval_word_stats_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_eval[2], filename='eval_word_stats_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_eval[3], filename='eval_word_stats_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_eval[4], filename='eval_word_stats_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_neg_words = list(np.union1d(pos_words, neg_words))\n",
    "relevant_words = np.union1d(pos_neg_words, player_words)\n",
    "irrelevant_words = list(set(word_2_counts.index).difference(set(relevant_words)))\n",
    "\n",
    "figs_all = []\n",
    "for const in score_vals:\n",
    "    data = [\n",
    "        get_trace(\"irrelevant\", irrelevant_words, const, \"yellow\", 5),\n",
    "        get_trace(\"relevant\", relevant_words, const, \"green\", 10)\n",
    "    ]\n",
    "    figs_all.append(go.Figure(data=data, layout=get_layout(const)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_all[0], filename='all_word_stats_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_all[1], filename='all_word_stats_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_all[2], filename='all_word_stats_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_all[3], filename='all_word_stats_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(figs_all[4], filename='all_word_stats_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter pair_occs_df for keywords in order to save time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(len(pair_occs_df))\n",
    "key_words = list(relevant_df[\"key_word\"].unique())\n",
    "pair_occs_df = pair_occs_df[pair_occs_df[\"word_1\"].isin(key_words)]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pair_occs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_norm_score(row, c_val, alpha=0, eps=0.0):\n",
    "    val_key = \"rel_count_%i\" % c_val\n",
    "    global_norm = row[\"global_val\"][val_key] if row[\"global_val\"] != 0 else 0\n",
    "    snapshot_norm = row[\"snapshot_val\"][val_key] if row[\"snapshot_val\"] != 0 else 0\n",
    "    # both normalization constant is missing\n",
    "    if global_norm == 0 and snapshot_norm == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (eps + (2.0 + alpha) * row[val_key]) / (eps + global_norm + snapshot_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) occ_score with different coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SCORE_CONST = ph.get(\"score_const\")\n",
    "SCORE_EPS = ph.get(\"score_eps\")\n",
    "SCORE_ALPHAS = ph.get(\"score_alphas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in SCORE_ALPHAS:\n",
    "    pair_occs_df[\"norm_c%i_a%i\" % (SCORE_CONST,a)] = pair_occs_df.apply(lambda x: calculate_norm_score(x, c_val=SCORE_CONST, alpha=a, eps=SCORE_EPS), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) occ_score with additional member (the former version is more sophisticated...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pair_occs_df[\"occ_score_mul_count\"] = pair_occs_df[\"count\"] * pair_occs_df[\"occ_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pair_occs_df[\"occ_score_plus_count\"] = pair_occs_df[\"count\"] + pair_occs_df[\"occ_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.) using Rayleigh for word frequency normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def rayleigh(x, s=1.0, exp=1):\n",
    "    var = s**2\n",
    "    return x / var * np.exp(-1.0 / (2*var) * np.power(x,exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x = np.arange(0,1,0.01)\n",
    "plt.plot(x,rayleigh(x, s=0.35, exp=1.0), label=\"s=0.35, exp=1.0\")\n",
    "plt.plot(x,rayleigh(x, s=0.15, exp=2.7), label=\"s=0.15, exp=2.7\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i.) calculate rayleigh decay factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "s_val_1 = 0.35\n",
    "pair_occs_df[\"rayleigh_%.2f\" % s_val_1] = pair_occs_df[\"word_2\"].apply(lambda x: rayleigh(word_2_counts[x], s=s_val_1, exp=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "s_val_2 = 0.15\n",
    "pair_occs_df[\"rayleigh_%.2f\" % s_val_2] = pair_occs_df[\"word_2\"].apply(lambda x: rayleigh(word_2_counts[x], s=s_val_2, exp=2.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii.) Rayleigh based scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for s in [0.35, 0.15]:\n",
    "    #pair_occs_df[\"rayleigh_%.2f_mul_score\" % s] = pair_occs_df[\"count\"] *  pair_occs_df[\"rayleigh_%.2f\" % s]\n",
    "    pair_occs_df[\"rayleigh_%.2f_plus_score\" % s] = pair_occs_df[\"count\"] +  pair_occs_df[\"rayleigh_%.2f\" % s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii.) occ_score + rayleigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for a in [1.0, 2.0, 5.0, 10.0, 20.0, 50.0]:\n",
    "    pair_occs_df[\"occ_score_alpha_%i_plus_rayleigh_0.35\" % a] = pair_occs_df[\"occ_score_alpha_%i\" % a] + pair_occs_df[\"rayleigh_0.35\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_models = et.load_w2v_models(\"%s/dim_%i/\" % (w2v_model_dir, ph.get(\"w2v_model_dim\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_w2v_toplist(w2v_models, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Jaccard and Cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_root_folder = ph.get(\"distance_root_folder\")\n",
    "jaccard_distances = et.load_distance_model(\"%s/jaccard.dist\" % distance_root_folder)\n",
    "cosine_distances = et.load_distance_model(\"%s/cosine.dist\" % distance_root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_distance_toplist(jaccard_distances, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_distance_toplist(cosine_distances, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_relevance_order(relevant_map):\n",
    "    relevant_df = pd.DataFrame(list(relevant_map.items()), columns=[\"word\",\"relevance\"])\n",
    "    relevant_df = relevant_df.sort_values(\"relevance\", ascending=False)\n",
    "    return list(relevant_df[\"word\"])\n",
    "\n",
    "def dcg(relevant_map, pred_order, k=None):\n",
    "    if k == None:\n",
    "        k = len(pred_order)\n",
    "    k = min(k, len(pred_order))\n",
    "    dcg_score = 0.0\n",
    "    for i in range(k):\n",
    "        word = pred_order[i]\n",
    "        if word in relevant_map:\n",
    "            dcg_score += relevant_map[word] / np.log(i+2)\n",
    "    return dcg_score\n",
    "\n",
    "def ndcg(relevant_map, pred_order, k=None):\n",
    "    if len(pred_order) == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        relevance_order = get_relevance_order(relevant_map)\n",
    "        dcg_val, idcg_val = dcg(relevant_map,pred_order,k=k), dcg(relevant_map,relevance_order,k=k)\n",
    "        return float(dcg_val) / idcg_val\n",
    "    \n",
    "relevant_map = {\"alma\":1.0,\"korte\":2.0,\"valami\":-5.0}\n",
    "print(get_relevance_order(relevant_map))\n",
    "print(ndcg(relevant_map, [\"szilva\",\"alma\"], k=1))\n",
    "print(ndcg(relevant_map, [\"alma\",\"korte\"], k=1))\n",
    "print(ndcg(relevant_map, [\"korte\",\"alma\"], k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_ndcg_for_relevant_record(relevant_df.ix[761], \"norm_c%i_a5\" % SCORE_CONST, exclude_player_words=True, top_k=None, general_words=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndcg_df.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relevant_df[relevant_df[\"key_word\"]==\"nadal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pair_occs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ndcg_for_relevant_record(rel_rec, score_col, exclude_player_words=True, top_k=None, general_words=None, verbose=False):\n",
    "    \"\"\"'general_words' must be a relevance dictionary.\"\"\"\n",
    "    time_id, key_word = rel_rec[\"time\"], rel_rec[\"key_word\"]\n",
    "    snapshot_id = \"%sT%s\" % (rel_rec[\"date\"], time_id)\n",
    "    # define relevant words\n",
    "    relevant_words = dict()\n",
    "    relevant_words.update(rel_rec[\"key_relevant_words\"])\n",
    "    relevant_words.update(rel_rec[\"opp_relevant_words\"])\n",
    "    if general_words != None:\n",
    "        relevant_words.update(general_words)\n",
    "    # define words to be excluded from the toplist    \n",
    "    if exclude_player_words:\n",
    "        to_be_excluded = rel_rec[\"key_exclude_words\"]\n",
    "    else:\n",
    "        to_be_excluded = None\n",
    "    # get toplist\n",
    "    if score_col == \"word_2_vec\":\n",
    "        pred_words = list(et.get_w2v_toplist(w2v_models, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded)[\"word_2\"])\n",
    "    elif score_col == \"jaccard\":\n",
    "        pred_words = list(et.get_distance_toplist(jaccard_distances, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded )[\"word_2\"])\n",
    "    elif score_col == \"cosine\":\n",
    "        pred_words = list(et.get_distance_toplist(cosine_distances, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded )[\"word_2\"])\n",
    "    else:\n",
    "        pred_words = list(et.get_toplist(pair_occs_df, [key_word], [snapshot_id], score_col=score_col, excluded_words=to_be_excluded)[\"word_2\"])\n",
    "    if verbose:\n",
    "        print(pred_words)\n",
    "        print(relevant_words)\n",
    "    ndcg_score = ndcg(relevant_words, pred_words, k=top_k)\n",
    "    return (snapshot_id, rel_rec[\"date\"], time_id, score_col, key_word, ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing, functools\n",
    "\n",
    "def get_ndcg_single_thread(top_k, row, general_words, score_col):\n",
    "    return get_ndcg_for_relevant_record(row, score_col, top_k=top_k, general_words=general_words)\n",
    "\n",
    "def get_ndcg_from_threads(top_k, time_ids, score_cols, general_words, n_threads=1):\n",
    "    print(len(relevant_df))\n",
    "    filtered_relevant_df = relevant_df[relevant_df[\"time\"].isin(time_ids)]\n",
    "    print(len(filtered_relevant_df))\n",
    "    ndcg_info_list = []\n",
    "    if n_threads > 1:\n",
    "        print(\"Calculating NDCG on %i threads\" % n_threads)\n",
    "    for idx, row in filtered_relevant_df.iterrows():\n",
    "        if n_threads == 1:\n",
    "            for score_col in score_cols:\n",
    "                ndcg_info_list += [get_ndcg_single_thread(top_k, row, general_words, score_col)]\n",
    "        else:\n",
    "            f_partial = functools.partial(get_ndcg_single_thread, top_k, row, general_words)\n",
    "            pool = multiprocessing.Pool(processes=n_threads)\n",
    "            res = pool.map(f_partial, score_cols)\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            ndcg_info_list += res\n",
    "    ndcg_df = pd.DataFrame(ndcg_info_list, columns=[\"snapshot_id\",\"date\",\"time\",\"score_id\",\"key_word\",\"ndcg\"])\n",
    "    return ndcg_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting general words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general_words = {\n",
    "    \"game\":MATCH_INFO_RELEVANCE,\n",
    "    \"play\":MATCH_INFO_RELEVANCE, \n",
    "    \"match\":MATCH_INFO_RELEVANCE,\n",
    "}\n",
    "if RELEVANCE_SUBSET == \"discriminative\":\n",
    "    general_words.update({\n",
    "        \"rolandgarros\":COMMON_WORD_RELEVANCE,\n",
    "        \"frenchopen\":COMMON_WORD_RELEVANCE,\n",
    "        \"clay\":COMMON_WORD_RELEVANCE,\n",
    "        \"slam\":COMMON_WORD_RELEVANCE,\n",
    "        \"set\":COMMON_WORD_RELEVANCE\n",
    "    })\n",
    "print(general_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cols = [\"word_2_vec\",\"jaccard\",\"cosine\",\"rel_count_%i\" % SCORE_CONST]\n",
    "score_cols += [\"norm_c%i_a%i\" % (SCORE_CONST,i) for i in [0,1,2,5]]\n",
    "print(score_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting time of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time_ids = [\"%.2i:00\" % t for t in TIME_HOUR_VALS]\n",
    "time_ids = [\"%.2i:00\" % t for t in [4,7,10,13,16,19]]\n",
    "time_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDCG in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ndcg_df = get_ndcg_from_threads(20, time_ids, score_cols, general_words, n_threads=len(time_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ndcg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndcg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean NDCG performance for score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcg_df.groupby(by=\"score_id\")[\"ndcg\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndcg_for_plots = ndcg_df[ndcg_df[\"score_id\"].isin([\"word_2_vec\",\"cosine\",\"jaccard\",\"rel_count_%s\" % SCORE_CONST,\"norm_c%s_a0\" % SCORE_CONST,\"norm_c%s_a5\" % SCORE_CONST])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paper_rc = {'lines.linewidth': 5,'lines.markersize': 20}              \n",
    "sns.set_context(\"paper\", rc = paper_rc, font_scale = 4.25)\n",
    "sns.set_style(\"whitegrid\")\n",
    "#sns.set(font=\"DejaVu Sans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) Compare co-occurence scores for snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(data=ndcg_for_plots, x=\"snapshot_id\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.) Compare co-occurence scores for date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(data=ndcg_for_plots, x=\"date\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii.)  Compare co-occurence scores for time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=ndcg_for_plots, x=\"time\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv.) Difference between players keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_player_perf(key_words):\n",
    "    score_filtered = ndcg_for_plots[ndcg_for_plots[\"key_word\"].isin(key_words)]\n",
    "    score_filtered = score_filtered[score_filtered[\"score_id\"] == \"norm_c%i_a5\" % SCORE_CONST]\n",
    "    score_filtered = score_filtered[score_filtered[\"date\"].isin([\"2017-06-08\",\"2017-06-09\",\"2017-06-10\",\"2017-06-11\"])]\n",
    "    g = sns.factorplot(data=score_filtered, x=\"snapshot_id\", y=\"ndcg\", hue=\"key_word\", size=10, aspect=3)\n",
    "    g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_names = [\"nadal\",\"wawrinka\",\"ostapenko\",\"halep\",\"murray\",\"djokovic\",\"cilic\",\"thiem\",\"pliskova\",\"bacsinszky\"]\n",
    "first_names = [\"rafael\",\"stan\",\"jelena\",\"simona\",\"andy\",\"novak\",\"marin\",\"dominic\",\"karolina\",\"timea\"]\n",
    "account_names = [\"@RafaelNadal\",\"@stanwawrinka\",\"@OstapenkoFC\",\"@Simona_Halep\",\"@andy_murray\",\"@DjokerNole\", \"@cilic_marin\", \"@ThiemDomi\", \"@KaPliskova\", \"@TimeaOfficial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_player_perf(last_names)\n",
    "show_player_perf(first_names)\n",
    "show_player_perf(account_names)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}