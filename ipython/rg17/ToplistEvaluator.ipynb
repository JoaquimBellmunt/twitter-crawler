{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from rg17 import evaluate_toplist as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font=\"DejaVu Sans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../pipelines/TrendApproximation.json\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_name_with_account_file_path = ph.get(\"player_name_with_accounts_file_path\")\n",
    "schedule_file_path = ph.get(\"schedule_file_path\")\n",
    "w2v_model_dir = ph.get(\"w2v_root_folder\")\n",
    "experiment_id = ph.get(\"experiment_id\")\n",
    "TIME_HOUR_VALS = ph.get(\"time_hour_vals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Player Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(player_name_with_account_file_path) as f:\n",
    "    player_account_map = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: should we use nicknames???\n",
    "    \n",
    "   * rafa\n",
    "   * djoko\n",
    "   * penko\n",
    "   * sveta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! Select main account for players: later we should decide whether we will enable multiple accounts in the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_account_map[\"Stan Wawrinka\"] = [\"stanwawrinka\"]\n",
    "player_account_map[\"Novak Djokovic\"] = [\"DjokerNole\"]\n",
    "player_account_map[\"Caroline Garcia\"] = [\"CaroGarcia\"]\n",
    "player_account_map[\"Caroline Wozniacki\"] = [\"CaroWozniacki\"]\n",
    "player_account_map[\"Marin Cilic\"] = [\"cilic_marin\"]\n",
    "player_account_map[\"Kristina Mladenovic\"] = [\"KikiMladenovic\"]\n",
    "player_account_map[\"Dominic Thiem\"] = [\"ThiemDomi\"]\n",
    "player_account_map[\"Rafael Nadal\"] = [\"RafaelNadal\"]\n",
    "player_account_map[\"Timea Bacsinszky\"] = [\"TimeaOfficial\"]\n",
    "player_account_map[\"Pablo Carreno Busta\"] = [\"pablocarreno91\"]\n",
    "player_account_map[\"Simona Halep\"] = [\"Simona_Halep\"]\n",
    "player_account_map[\"Andy Murray\"] = [\"andy_murray\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df = pd.read_csv(schedule_file_path, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_categories = [\"boy\", \"girl\", \"wheelchair\", \"legends over 45\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert start dates to UTC for the proper evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"startDate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utc_hour_map = {\n",
    "    \"11:00 AM\" : 9,\n",
    "    \"10:00 AM\" : 8,\n",
    "    \"12:00 PM\" : 10,\n",
    "    \"2:00 PM\" : 12,\n",
    "    \"11:30 AM\" : 10, # hour was rounded up\n",
    "    \"3:00 PM\" : 13,\n",
    "    \"12:45 PM\" : 11 # hour was rounded up\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"] = schedule_df[\"startDate\"].apply(lambda x: utc_hour_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Schedule\n",
    "\n",
    "   * only Single matches are kept\n",
    "   * only important categories are kept (Men's, Women's, Legends under 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_categories(match_cat, excluded_cats=excluded_categories):\n",
    "    match_cat_lower = match_cat.lower()\n",
    "    keep_this = True\n",
    "    for cat in excluded_cats:\n",
    "        if cat in match_cat_lower:\n",
    "            keep_this = False\n",
    "            break\n",
    "    if not (\"final\" in match_cat_lower and \"single\" in match_cat_lower):\n",
    "        keep_this = False\n",
    "    return keep_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df = schedule_df[schedule_df[\"matchHeader\"].apply(filter_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(schedule_df), len(finals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single finals\n",
    "\n",
    "   * **canceled** matches are not excluded because people may talk about this events as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player name parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players = list(set(finals_df[\"playerName active\"]).union(finals_df[\"playerName opponent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map = {}\n",
    "for player in players:\n",
    "    player_info_map[player] = {\n",
    "        \"name_parts\": [p.lower() for p in player.split()],\n",
    "        \"accounts\": [\"@\" + et.transform_account_name(a, remove_digits=False, remove_under_score=False, to_lower=False) for a in player_account_map[player]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show multi-account players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for player, info in player_info_map.items():\n",
    "    if len(info[\"accounts\"]) > 1:\n",
    "        print(player, info[\"accounts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pd.read_csv(\"/mnt/idms/fberes/network/combined_occ/occ_scores/%s_with_scores.csv\" % experiment_id, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_set = set(pair_occs_df[\"word_2\"].unique())\n",
    "word_1_set = set(pair_occs_df[\"word_1\"].unique())\n",
    "len(word_1_set), len(word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_missing_words(info_key, word_set):\n",
    "    for player, info in player_info_map.items():\n",
    "        diff = list(set(info[info_key]).difference(word_set))\n",
    "        if len(diff) != 0:\n",
    "            print(\"%s: %s missing!\" % (player, diff))\n",
    "            \n",
    "def show_matching_words(info_key, word_set):\n",
    "    for player, info in player_info_map.items():\n",
    "        match = list(set(info[info_key]).intersection(word_set))\n",
    "        print(\"%s: %s\" % (player, match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Checking names (All names are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_matching_words(\"name_parts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Checking account names (All main account are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"accounts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"accounts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_matching_words(\"accounts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant player words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df[finals_df[\"matchScore\"] == \"Cancelled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2relevance(values, relevance):\n",
    "    return dict(zip(values, relevance * np.ones(len(values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: add players who play at the same time but not with our player - with negative relevance!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Other relevant events\n",
    "\n",
    "   * birthday for nadal\n",
    "   * injuries for other players?\n",
    "   * wheather? rain? etc???\n",
    "   * cancelled match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winner Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winner_synonyms = [\"win\",\"won\",\"victori\",\"triumph\"]#,\"winner\"\n",
    "#winner_synonyms += [\"champ\",\"champion\",\"king\"]\n",
    "#winner_synonyms += [\"congrat\",\"congratul\"]\n",
    "#winner_synonyms += [\"title\",\"trophi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loser Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loser_synonyms = [\"lose\", \"lost\", \"beaten\"]#, \"loser\"]\n",
    "#loser_synonyms += [\"defeat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_relevance_record(date, time, utc_hour, winner, loser, score):\n",
    "    if score == \"Cancelled\":\n",
    "        to_iterate_on = [(winner, loser, None),(loser, winner, None)]\n",
    "    else:\n",
    "        to_iterate_on = [(winner, loser, 1),(loser, winner, 0)]\n",
    "    res = []\n",
    "    for p1, p2, is_winner in to_iterate_on:\n",
    "        n1, n2 = player_info_map[p1][\"name_parts\"], player_info_map[p2][\"name_parts\"]\n",
    "        acc1, acc2 = player_info_map[p1][\"accounts\"], player_info_map[p2][\"accounts\"]\n",
    "        for w in n1+acc1:\n",
    "            player_relevant = dict()\n",
    "            # set relevance for winner information (only after the match started)\n",
    "            if time >= utc_hour:\n",
    "                # in case of \"Cancelled\" there is only zero relevance\n",
    "                if is_winner == 1:\n",
    "                    player_relevant.update(list2relevance(winner_synonyms, 4.0))\n",
    "                    player_relevant.update(list2relevance(loser_synonyms, -4.0))\n",
    "                elif is_winner == 0:\n",
    "                    player_relevant.update(list2relevance(winner_synonyms, -4.0))\n",
    "                    player_relevant.update(list2relevance(loser_synonyms, -4.0))\n",
    "            # set relevance for final categories\n",
    "            if date in [\"2017-06-06\",\"2017-06-07\"]:\n",
    "                player_relevant.update(list2relevance([\"quarters\",\"quarter\",\"final\"], 3.0))\n",
    "            elif date in [\"2017-06-08\",\"2017-06-09\"]:\n",
    "                player_relevant.update(list2relevance([\"semi\",\"final\"], 3.0))\n",
    "            elif date in [\"2017-06-10\",\"2017-06-11\"]:\n",
    "                player_relevant.update(list2relevance([\"final\"], 3.0))\n",
    "            # set relevance for opponent information\n",
    "            opponent_relevant = list2relevance(n2+acc2, 5.0)\n",
    "            res.append([date, \"%.2i:00\" % time, p1, is_winner, w, player_relevant, p2, opponent_relevant])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_infos = []\n",
    "for idx, row in finals_df.iterrows():\n",
    "    date, utc_hour, winner, loser, score = row[\"date\"], row[\"utc_start_hour\"], row[\"playerName active\"], row[\"playerName opponent\"], row[\"matchScore\"]\n",
    "    for time in TIME_HOUR_VALS:\n",
    "        relevant_infos += get_relevance_record(date, time, utc_hour, winner, loser, score)\n",
    "relevant_df = pd.DataFrame(relevant_infos, columns=[\"date\",\"time\",\"player\",\"is_winner\",\"key_word\", \"key_relevant_words\", \"opponent\",\"opp_relevant_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(relevant_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving daily keywors to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggr_keyword_by_day = relevant_df.groupby(by=\"date\")[\"key_word\"].aggregate(lambda x: set(x))\n",
    "aggr_keyword_by_day.to_csv(ph.get(\"keywords_for_eval_path\"), sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: wawrinka loser information has relevance only in snapshots after match start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df[relevant_df[\"date\"]==\"2017-06-11\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average fraction for word_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts = pair_occs_df.groupby(by=[\"word_2\"])[\"count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts[\"@simonahalep\"], word_2_counts[\"simona\"], word_2_counts[\"halep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts[\"@rafaelnadal\"], word_2_counts[\"rafael\"], word_2_counts[\"nadal\"], word_2_counts[\"rafa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts[\"win\"], word_2_counts[\"champion\"], word_2_counts[\"lose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_counts[\"tennis\"], word_2_counts[\"rolandgarros\"], word_2_counts[\"frenchopen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter pair_occs_df for keywords in order to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(pair_occs_df))\n",
    "key_words = list(relevant_df[\"key_word\"].unique())\n",
    "pair_occs_df = pair_occs_df[pair_occs_df[\"word_1\"].isin(key_words)]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_occ_score(row, c=1.0, alpha=1.0):\n",
    "    return (c + (1.0+alpha) * row[\"count\"]) / (c + row[\"global_val\"] + row[\"snapshot_val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) occ_score with different coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SCORE_CONST = ph.get(\"score_const\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"occ_score\"] = pair_occs_df.apply(lambda x: calculate_occ_score(x, c=SCORE_CONST), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in [2.0, 3.0, 5.0, 10.0, 20.0, 50.0]:#, 100.0, 200.0, 500.0]:\n",
    "    pair_occs_df[\"occ_score_alpha_%i\" % a] = pair_occs_df.apply(lambda x: calculate_occ_score(x, c=SCORE_CONST, alpha=a), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) occ_score with additional member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"occ_score_mul_count\"] = pair_occs_df[\"count\"] * pair_occs_df[\"occ_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"occ_score_plus_count\"] = pair_occs_df[\"count\"] + pair_occs_df[\"occ_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.) using Rayleigh for word frequency normalization\n",
    "\n",
    "## Rayleigh is used with modified exponent!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rayleigh(x, s=1.0, exp=1):\n",
    "    var = s**2\n",
    "    return x / var * np.exp(-1.0 / (2*var) * np.power(x,exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(0,1,0.01)\n",
    "plt.plot(x,rayleigh(x, s=0.35, exp=1.0), label=\"s=0.35, exp=1.0\")\n",
    "plt.plot(x,rayleigh(x, s=0.15, exp=2.7), label=\"s=0.15, exp=2.7\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i.) calculate rayleigh decay factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_val_1 = 0.35\n",
    "pair_occs_df[\"rayleigh_%.2f\" % s_val_1] = pair_occs_df[\"word_2\"].apply(lambda x: rayleigh(word_2_counts[x], s=s_val_1, exp=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_val_2 = 0.15\n",
    "pair_occs_df[\"rayleigh_%.2f\" % s_val_2] = pair_occs_df[\"word_2\"].apply(lambda x: rayleigh(word_2_counts[x], s=s_val_2, exp=2.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii.) Rayleigh based scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in [0.35, 0.15]:\n",
    "    pair_occs_df[\"rayleigh_%.2f_mul_score\" % s] = pair_occs_df[\"count\"] *  pair_occs_df[\"rayleigh_%.2f\" % s]\n",
    "    pair_occs_df[\"rayleigh_%.2f_plus_score\" % s] = pair_occs_df[\"count\"] +  pair_occs_df[\"rayleigh_%.2f\" % s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_models = et.load_w2v_models(\"%s/dim_%i/\" % (w2v_model_dir, ph.get(\"w2v_model_dim\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_w2v_toplist(w2v_models, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Jaccard and Cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_distance_model(distance_model_path):\n",
    "    \"\"\"Load distance model (Jaccard or Cosine) trained for snapshots\"\"\"\n",
    "    return pd.read_csv(distance_model_path, sep=\"|\")\n",
    "\n",
    "def distance_query(distance_df, key_word, snapshot_id, top_k=None):\n",
    "    \"\"\"Handle distance request for only one key word and snapshot id.\"\"\"\n",
    "    out_df = distance_df[(distance_df[\"word_1\"] == key_word) & (distance_df[\"snapshot_id\"] == snapshot_id)]\n",
    "    out_df = out_df.sort_values(\"distance\", ascending=True)\n",
    "    if top_k != None:\n",
    "        out_df = out_df.head(top_k)\n",
    "    out_df[\"time\"] = out_df[\"snapshot_id\"]\n",
    "    return out_df[[\"time\",\"word_1\",\"word_2\",\"distance\"]]\n",
    "\n",
    "def get_distance_toplist(distance_df, key_words, snapshot_ids, top_k):\n",
    "    \"\"\"Get most similar words based on 'distance_df'. \n",
    "    If more than 1 snapshot id is specified then there could be duplications in the data!\"\"\"\n",
    "    dfs = [distance_query(distance_df, kw, sid, top_k) for kw in key_words for sid in snapshot_ids]\n",
    "    return pd.concat(dfs).sort_values(\"distance\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_root_folder = ph.get(\"distance_root_folder\")\n",
    "jaccard_distances = load_distance_model(\"%s/jaccard.dist\" % distance_root_folder)\n",
    "cosine_distances = load_distance_model(\"%s/cosine.dist\" % distance_root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_distance_toplist(jaccard_distances, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_distance_toplist(cosine_distances, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random shuffle is not implemented yet for ties!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_relevance_order(relevant_map):\n",
    "    relevant_df = pd.DataFrame(list(relevant_map.items()), columns=[\"word\",\"relevance\"])\n",
    "    relevant_df = relevant_df.sort_values(\"relevance\", ascending=False)\n",
    "    return list(relevant_df[\"word\"])\n",
    "\n",
    "def dcg(relevant_map, pred_order, k=None):\n",
    "    if k == None:\n",
    "        k = len(pred_order)\n",
    "    k = min(k, len(pred_order))\n",
    "    dcg_score = 0.0\n",
    "    for i in range(k):\n",
    "        word = pred_order[i]\n",
    "        if word in relevant_map:\n",
    "            dcg_score += relevant_map[word] / np.log(i+2)\n",
    "    return dcg_score\n",
    "\n",
    "def ndcg(relevant_map, pred_order, k=None):\n",
    "    if len(pred_order) == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        relevance_order = get_relevance_order(relevant_map)\n",
    "        dcg_val, idcg_val = dcg(relevant_map,pred_order,k=k), dcg(relevant_map,relevance_order,k=k)\n",
    "        return float(dcg_val) / idcg_val\n",
    "    \n",
    "relevant_map = {\"alma\":1.0,\"korte\":2.0,\"valami\":-5.0}\n",
    "print(get_relevance_order(relevant_map))\n",
    "print(ndcg(relevant_map, [\"szilva\",\"alma\"], k=1))\n",
    "print(ndcg(relevant_map, [\"alma\",\"korte\"], k=1))\n",
    "print(ndcg(relevant_map, [\"korte\",\"alma\"], k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: remove player name related words from the predicted toplist..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: send warning if toplist is empty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ndcg_for_relevant_record(rel_rec, score_col, top_k=None, general_words=None):\n",
    "    \"\"\"'general_words' must be a relevance dictionary\"\"\"\n",
    "    time_id, key_word = rel_rec[\"time\"], rel_rec[\"key_word\"]\n",
    "    snapshot_id = \"%sT%s\" % (rel_rec[\"date\"], time_id)\n",
    "    relevant_words = dict()\n",
    "    relevant_words.update(rel_rec[\"key_relevant_words\"] )\n",
    "    relevant_words.update(rel_rec[\"opp_relevant_words\"])\n",
    "    if general_words != None:\n",
    "        relevant_words.update(general_words)\n",
    "    if score_col == \"w2v_score\":\n",
    "        pred_words = list(et.get_w2v_toplist(w2v_models, [key_word], [snapshot_id], top_k=top_k )[\"word_2\"])\n",
    "    elif score_col == \"jaccard\":\n",
    "        pred_words = list(get_distance_toplist(jaccard_distances, [key_word], [snapshot_id], top_k=top_k )[\"word_2\"])\n",
    "    elif score_col == \"cosine\":\n",
    "        pred_words = list(get_distance_toplist(cosine_distances, [key_word], [snapshot_id], top_k=top_k )[\"word_2\"])\n",
    "    else:\n",
    "        pred_words = list(et.get_toplist(pair_occs_df, [key_word], [snapshot_id], score_col=score_col)[\"word_2\"])\n",
    "    ndcg_score = ndcg(relevant_words, pred_words, k=top_k)\n",
    "    return (snapshot_id, rel_rec[\"date\"], time_id, score_col, key_word, ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing, functools\n",
    "\n",
    "def get_ndcg_single_thread(top_k, row, general_words, score_col):\n",
    "    return get_ndcg_for_relevant_record(row, score_col, top_k=top_k, general_words=general_words)\n",
    "\n",
    "def get_ndcg_from_threads(top_k, time_ids, score_cols, general_words, n_threads=1):\n",
    "    print(len(relevant_df))\n",
    "    filtered_relevant_df = relevant_df[relevant_df[\"time\"].isin(time_ids)]\n",
    "    print(len(filtered_relevant_df))\n",
    "    ndcg_info_list = []\n",
    "    for idx, row in filtered_relevant_df.iterrows():\n",
    "        if n_threads == 1:\n",
    "            for score_col in score_cols:\n",
    "                ndcg_info_list += [get_ndcg_single_thread(top_k, row, general_words, score_col)]\n",
    "        else:\n",
    "            f_partial = functools.partial(get_ndcg_single_thread, top_k, row, general_words)\n",
    "            pool = multiprocessing.Pool(processes=n_threads)\n",
    "            res = pool.map(f_partial, score_cols)\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            ndcg_info_list += res\n",
    "    ndcg_df = pd.DataFrame(ndcg_info_list, columns=[\"snapshot_id\",\"date\",\"time\",\"score_id\",\"key_word\",\"ndcg\"])\n",
    "    return ndcg_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_cols = [\n",
    "    \"w2v_score\",\n",
    "    \"jaccard\",\n",
    "    \"cosine\",\n",
    "    \"count\",\n",
    "    \"occ_score\",\n",
    "    \"occ_score_alpha_2\",\n",
    "    \"occ_score_alpha_3\",\n",
    "    \"occ_score_alpha_5\",\n",
    "    \"occ_score_alpha_10\",\n",
    "    \"occ_score_alpha_20\",\n",
    "    \"occ_score_alpha_50\",\n",
    "    #\"occ_score_alpha_100\",\n",
    "    #\"occ_score_alpha_200\",\n",
    "    #\"occ_score_alpha_500\",\n",
    "    \"occ_score_mul_count\",\n",
    "    \"occ_score_plus_count\",\n",
    "    \"rayleigh_0.35_mul_score\",\n",
    "    \"rayleigh_0.35_plus_score\",\n",
    "    \"rayleigh_0.15_mul_score\",\n",
    "    \"rayleigh_0.15_plus_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "784*len(score_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "general_words = {\"play\":4.0, \"match\":4.0, \"rolandgarros\":-5.0, \"frenchopen\":-5.0, \"tennis\":-5.0}\n",
    "#general_words = {\"play\":4.0, \"match\":4.0}\n",
    "#time_ids = [\"%.2i:00\" % t for t in TIME_HOUR_VALS]\n",
    "time_ids = [\"07:00\",\"10:00\",\"13:00\",\"16:00\",\"19:00\"]\n",
    "ndcg_df = get_ndcg_from_threads(20, time_ids, score_cols, general_words, n_threads=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ndcg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndcg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean NDCG performance for score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcg_df.groupby(by=\"score_id\")[\"ndcg\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) Compare co-occurence scores for date\n",
    "\n",
    "   * the baseline score is the best (the fraction of co-occurences)\n",
    "   * occ_score_2 gives similar results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=ndcg_df, x=\"date\", y=\"ndcg\", hue=\"score_id\", size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "#score_col = \"occ_score\"\n",
    "score_col = \"rayleigh_0.35_plus_score\"\n",
    "#score_col = \"count\"\n",
    "et.get_toplist(pair_occs_df, [\"nadal\"], [\"2017-06-11T16:00\"], score_col=score_col)[[\"word_1\",\"word_2\",score_col]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "et.get_w2v_toplist(w2v_models, [\"nadal\"], [\"2017-06-11T16:00\"], top_k=10)[[\"word_1\",\"word_2\",\"w2v_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndcg_df[(ndcg_df[\"snapshot_id\"]==\"2017-06-11T16:00\") & (ndcg_df[\"key_word\"]==\"nadal\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.)  Compare co-occurence scores for time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=ndcg_df, x=\"time\", y=\"ndcg\", hue=\"score_id\", size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# difference between players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words = [\"nadal\",\"wawrinka\",\"ostapenko\",\"halep\",\"murray\",\"djokovic\",\"cilic\",\"pliskova\",\"bacsinszky\"]\n",
    "score_filtered = ndcg_df[ndcg_df[\"key_word\"].isin(key_words)]\n",
    "sns.factorplot(data=score_filtered, x=\"date\", y=\"ndcg\", hue=\"key_word\", size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formerly accounts had low performance, but after dropping stop words it improved a lot!\n",
    "\n",
    "**@OstapenkoFC** is probably a bad account... less popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words = [\"@RafaelNadal\",\"@stanwawrinka\",\"@OstapenkoFC\",\"@Simona_Halep\",\"@andy_murray\",\"@DjokerNole\", \"@cilic_marin\", \"@KaPliskova\", \"@TimeaOfficial\"]\n",
    "score_filtered = ndcg_df[ndcg_df[\"key_word\"].isin(key_words)]\n",
    "sns.factorplot(data=score_filtered, x=\"date\", y=\"ndcg\", hue=\"key_word\", size=8)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}