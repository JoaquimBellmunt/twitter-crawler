{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from rg17 import evaluate_toplist as et\n",
    "from rg17 import visualization as visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font=\"DejaVu Sans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../pipelines/TrendApproximation.json\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_name_with_account_file_path = ph.get(\"player_name_with_accounts_file_path\")\n",
    "schedule_file_path = ph.get(\"schedule_file_path\")\n",
    "w2v_model_dir = ph.get(\"w2v_root_folder\")\n",
    "experiment_id = ph.get(\"experiment_id\")\n",
    "TIME_HOUR_VALS = ph.get(\"time_hour_vals\")\n",
    "RELEVANCE_TYPE = ph.get(\"relevance_type\")\n",
    "RELEVANCE_SUBSET = ph.get(\"relevance_subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Player Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(player_name_with_account_file_path) as f:\n",
    "    player_account_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_account_map[\"Stan Wawrinka\"] = [\"stanwawrinka\"]\n",
    "player_account_map[\"Novak Djokovic\"] = [\"DjokerNole\"]\n",
    "player_account_map[\"Caroline Garcia\"] = [\"CaroGarcia\"]\n",
    "player_account_map[\"Caroline Wozniacki\"] = [\"CaroWozniacki\"]\n",
    "player_account_map[\"Marin Cilic\"] = [\"cilic_marin\"]\n",
    "player_account_map[\"Kristina Mladenovic\"] = [\"KikiMladenovic\"]\n",
    "player_account_map[\"Dominic Thiem\"] = [\"ThiemDomi\"]\n",
    "player_account_map[\"Rafael Nadal\"] = [\"RafaelNadal\"]\n",
    "player_account_map[\"Timea Bacsinszky\"] = [\"TimeaOfficial\"]\n",
    "player_account_map[\"Pablo Carreno Busta\"] = [\"pablocarreno91\"]\n",
    "player_account_map[\"Simona Halep\"] = [\"Simona_Halep\"]\n",
    "player_account_map[\"Andy Murray\"] = [\"andy_murray\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df = pd.read_csv(schedule_file_path, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_categories = [\"boy\", \"girl\", \"wheelchair\", \"legends over 45\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert start dates to UTC for the proper evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"startDate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utc_hour_map = {\n",
    "    \"11:00 AM\" : 9,\n",
    "    \"10:00 AM\" : 8,\n",
    "    \"12:00 PM\" : 10,\n",
    "    \"2:00 PM\" : 12,\n",
    "    \"11:30 AM\" : 10, # hour was rounded up\n",
    "    \"3:00 PM\" : 13,\n",
    "    \"12:45 PM\" : 11 # hour was rounded up\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"] = schedule_df[\"startDate\"].apply(lambda x: utc_hour_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df[\"utc_start_hour\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Schedule\n",
    "\n",
    "   * only Single matches are kept\n",
    "   * only important categories are kept (Men's, Women's, Legends under 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_categories(match_cat, excluded_cats=excluded_categories):\n",
    "    match_cat_lower = match_cat.lower()\n",
    "    keep_this = True\n",
    "    for cat in excluded_cats:\n",
    "        if cat in match_cat_lower:\n",
    "            keep_this = False\n",
    "            break\n",
    "    if not (\"final\" in match_cat_lower and \"single\" in match_cat_lower):\n",
    "        keep_this = False\n",
    "    return keep_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df = schedule_df[schedule_df[\"matchHeader\"].apply(filter_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(schedule_df), len(finals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single finals\n",
    "\n",
    "   * **canceled** matches are not excluded because people may talk about this events as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players_by_date = {}\n",
    "for idx, row in finals_df.iterrows():\n",
    "    date, player_1, player_2 = row[\"date\"], row[\"playerName active\"], row[\"playerName opponent\"]\n",
    "    if not date in players_by_date:\n",
    "        players_by_date[date] = []\n",
    "    players_by_date[date] += [player_1, player_2]\n",
    "players_by_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player name parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players = list(set(finals_df[\"playerName active\"]).union(finals_df[\"playerName opponent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map = {}\n",
    "for player in players:\n",
    "    player_info_map[player] = {\n",
    "        \"name_parts\": [p.lower() for p in player.split()],\n",
    "        \"accounts\": [\"@\" + et.transform_account_name(a, remove_digits=False, remove_under_score=False, to_lower=False) for a in player_account_map[player]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show multi-account players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for player, info in player_info_map.items():\n",
    "    if len(info[\"accounts\"]) > 1:\n",
    "        print(player, info[\"accounts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_info_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pd.read_csv(\"/mnt/idms/fberes/network/combined_occ/occ_scores/%s_with_scores.csv\" % experiment_id, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting string to dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pair_occs_df[\"global_val\"] = pair_occs_df[\"global_val\"].apply(eval)\n",
    "pair_occs_df[\"snapshot_val\"] = pair_occs_df[\"snapshot_val\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_set = set(pair_occs_df[\"word_2\"].unique())\n",
    "word_1_set = set(pair_occs_df[\"word_1\"].unique())\n",
    "len(word_1_set), len(word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_missing_words(info_key, word_set):\n",
    "    for player, info in player_info_map.items():\n",
    "        diff = list(set(info[info_key]).difference(word_set))\n",
    "        if len(diff) != 0:\n",
    "            print(\"%s: %s missing!\" % (player, diff))\n",
    "            \n",
    "def show_matching_words(info_key, word_set):\n",
    "    for player, info in player_info_map.items():\n",
    "        match = list(set(info[info_key]).intersection(word_set))\n",
    "        print(\"%s: %s\" % (player, match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Checking names (All names are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"name_parts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_matching_words(\"name_parts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Checking account names (All main account are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"accounts\", word_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_missing_words(\"accounts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_matching_words(\"accounts\", word_1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant player words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finals_df[finals_df[\"matchScore\"] == \"Cancelled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2relevance(values, relevance):\n",
    "    return dict(zip(values, relevance * np.ones(len(values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Other relevant events\n",
    "\n",
    "   * birthday for nadal\n",
    "   * injuries for other players?\n",
    "   * wheather? rain? etc???\n",
    "   * cancelled match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RELEVANCE_TYPE == \"binary\":\n",
    "    OPPONENT_RELEVANCE = 1.0\n",
    "    WINNER_INFO_RELEVANCE = 1.0\n",
    "    MATCH_INFO_RELEVANCE = 1.0\n",
    "    OTHER_PLAYER_RELEVANCE = 0.0\n",
    "    COMMON_WORD_RELEVANCE = -1.0    \n",
    "else:\n",
    "    OPPONENT_RELEVANCE = 5.0\n",
    "    WINNER_INFO_RELEVANCE = 4.0\n",
    "    MATCH_INFO_RELEVANCE = 3.0\n",
    "    OTHER_PLAYER_RELEVANCE = 0.0\n",
    "    COMMON_WORD_RELEVANCE = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winner Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winner_synonyms = [\"win\",\"won\",\"winner\",\"victori\",\"triumph\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loser Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loser_synonyms = [\"lose\", \"lost\", \"beaten\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_relevance_record(relevance_subset, date, time, utc_hour, winner, loser, score):\n",
    "    daily_player_keys = []\n",
    "    for player in players_by_date[date]:\n",
    "        if player != winner and player != loser:\n",
    "            daily_player_keys += player_info_map[player][\"name_parts\"]\n",
    "            daily_player_keys += player_info_map[player][\"accounts\"]\n",
    "    #print(winner, loser, daily_player_keys)\n",
    "    if score == \"Cancelled\":\n",
    "        to_iterate_on = [(winner, loser, None),(loser, winner, None)]\n",
    "    else:\n",
    "        to_iterate_on = [(winner, loser, 1),(loser, winner, 0)]\n",
    "    res = []\n",
    "    for p1, p2, is_winner in to_iterate_on:\n",
    "        n1, n2 = player_info_map[p1][\"name_parts\"], player_info_map[p2][\"name_parts\"]\n",
    "        acc1, acc2 = player_info_map[p1][\"accounts\"], player_info_map[p2][\"accounts\"]\n",
    "        for w in n1+acc1:\n",
    "            key_exclude = n1+acc1\n",
    "            key_exclude.remove(w)\n",
    "            player_relevant = dict()\n",
    "            # set relevance for winner information (only after the match started)\n",
    "            if time > utc_hour:\n",
    "                # in case of \"Cancelled\" there is only zero relevance\n",
    "                if is_winner == 1:\n",
    "                    player_relevant.update(list2relevance(winner_synonyms, WINNER_INFO_RELEVANCE))\n",
    "                    if relevance_subset != \"positive\":\n",
    "                        player_relevant.update(list2relevance(loser_synonyms, -WINNER_INFO_RELEVANCE))\n",
    "                elif is_winner == 0:\n",
    "                    if relevance_subset != \"positive\":\n",
    "                        player_relevant.update(list2relevance(winner_synonyms, -WINNER_INFO_RELEVANCE))\n",
    "                    player_relevant.update(list2relevance(loser_synonyms, WINNER_INFO_RELEVANCE))\n",
    "            # set relevance for final categories\n",
    "            if date in [\"2017-06-06\",\"2017-06-07\"]:\n",
    "                player_relevant.update(list2relevance([\"quarter\",\"final\"], MATCH_INFO_RELEVANCE))\n",
    "            elif date in [\"2017-06-08\",\"2017-06-09\"]:\n",
    "                player_relevant.update(list2relevance([\"semi\",\"final\"], MATCH_INFO_RELEVANCE))\n",
    "            elif date in [\"2017-06-10\",\"2017-06-11\"]:\n",
    "                player_relevant.update(list2relevance([\"final\"], MATCH_INFO_RELEVANCE))\n",
    "            # set relevance for opponent information\n",
    "            opponent_relevant = list2relevance(n2+acc2, OPPONENT_RELEVANCE)\n",
    "            other_player_relevant = list2relevance(daily_player_keys, OTHER_PLAYER_RELEVANCE)\n",
    "            res.append([date, \"%.2i:00\" % time, p1, is_winner, w, key_exclude, player_relevant,  p2, opponent_relevant, other_player_relevant])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_infos = []\n",
    "for idx, row in finals_df.iterrows():\n",
    "    date, utc_hour, winner, loser, score = row[\"date\"], row[\"utc_start_hour\"], row[\"playerName active\"], row[\"playerName opponent\"], row[\"matchScore\"]\n",
    "    for time in TIME_HOUR_VALS:\n",
    "        relevant_infos += get_relevance_record(RELEVANCE_SUBSET, date, time, utc_hour, winner, loser, score)\n",
    "relevant_df = pd.DataFrame(relevant_infos, columns=[\"date\",\"time\",\"player\",\"is_winner\",\"key_word\", \"key_exclude_words\", \"key_relevant_words\", \"opponent\",\"opp_relevant_words\", \"other_player_relevant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(relevant_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving daily keywors to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggr_keyword_by_day = relevant_df.groupby(by=\"date\")[\"key_word\"].aggregate(lambda x: set(x))\n",
    "aggr_keyword_by_day.to_csv(ph.get(\"keywords_for_eval_path\"), sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: wawrinka loser information has relevance only in snapshots after match start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_df[relevant_df[\"date\"]==\"2017-06-11\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pair_occs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter pair_occs_df for keywords in order to save time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(len(pair_occs_df))\n",
    "key_words = list(relevant_df[\"key_word\"].unique())\n",
    "pair_occs_df = pair_occs_df[pair_occs_df[\"word_1\"].isin(key_words)]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_2 frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_cols = [\"global_val\",\"snapshot_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_2_stats = pair_occs_df.groupby(by=[\"word_2\"])[stat_cols].mean()\n",
    "word_2_counts = pair_occs_df.groupby(by=[\"word_2\"])[\"date\"].count()\n",
    "word_2_counts_norm = word_2_counts / word_2_counts.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_factor = np.floor(np.log(word_2_counts / 5) / np.log(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"frequency_val\"] = pair_occs_df[\"word_2\"].apply(lambda x: 0.0 if freq_factor[x] < 1 else 1.0 / freq_factor[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate normalization coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot_weight = ph.get(\"snapshot_weight\")\n",
    "frequency_weight = ph.get(\"frequency_weight\")\n",
    "print(snapshot_weight, frequency_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"r\"] = (1.0 - (snapshot_weight + frequency_weight)) * pair_occs_df[\"global_val\"] + snapshot_weight * pair_occs_df[\"snapshot_val\"] + frequency_weight * pair_occs_df[\"frequency_val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) rel_count_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_vals = ph.get(\"score_c_vals\")\n",
    "print(score_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rel_count_calculator(row, c=0.0, ):\n",
    "    num = row[\"word_2_count\"] + row[\"r\"] * c\n",
    "    denom = row[\"word_1_count\"] + c\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in score_vals:\n",
    "    pair_occs_df[\"rel_count_c%i\" % c] = pair_occs_df.apply(lambda x: rel_count_calculator(x, c=c), axis=1)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"rel_count_c5\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) norm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in score_vals:\n",
    "    pair_occs_df[\"norm_c%i\" % c] = pair_occs_df[\"rel_count_c%i\" % c] / pair_occs_df[\"r\"]\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"norm_c5\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.) using Rayleigh for word frequency normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def rayleigh(x, s=1.0, exp=1, N=1.0):\n",
    "    var = s**2\n",
    "    return x / var * np.exp(-1.0 / (2*var) * np.power(x,exp)) * (1.0/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x = np.arange(0,1,0.01)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(x,rayleigh(x, s=0.12, exp=2.0, N=10.0), label=\"s=0.12, exp=2.0\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pair_occs_df[\"rayleigh\"] = pair_occs_df[\"word_2\"].apply(lambda x: rayleigh(word_2_counts_norm[x], s=0.15, exp=2.0, N=10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for c in score_vals: \n",
    "    pair_occs_df[\"norm_c%i_plus_ray\" % c] = pair_occs_df[\"norm_c%i\" % c] + pair_occs_df[\"rayleigh\"]\n",
    "    pair_occs_df[\"rel_count_c%i_plus_ray\" % c] = pair_occs_df[\"rel_count_c%i\" % c] + pair_occs_df[\"rayleigh\"]\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of word statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def get_x_y_simple(words):\n",
    "    x_arr = [word_2_stats.ix[w][\"global_val\"] for w in words]\n",
    "    y_arr = [word_2_counts[w] for w in words]\n",
    "    return x_arr, y_arr\n",
    "    \n",
    "def get_x_y_ray(words):\n",
    "    x_arr = [word_2_stats.ix[w][\"global_val\"] for w in words]\n",
    "    y_arr = [rayleigh(word_2_counts_norm[w], s=0.15, exp=2.0, N=10.0) for w in words]\n",
    "    return x_arr, y_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluated word statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. ) without rayleigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pos_words = [\"game\",\"play\",\"match\",\"quarter\",\"final\"] + winner_synonyms + loser_synonyms + [\"king\"]\n",
    "neg_words = [\"rolandgarros\",\"frenchopen\",\"clay\",\"slam\",\"set\",\"round\",\"rg17\",\"rolandgarros2017\",\"french\",\"open\",\"rg2017\"]\n",
    "player_words = list(relevant_df[\"key_word\"])\n",
    "\n",
    "word_sets = [\n",
    "    (\"players\", player_words, \"blue\", 5),\n",
    "    (\"positive relevance\", pos_words, \"green\", 10),\n",
    "    (\"negative relevance\", neg_words, \"red\", 10)\n",
    "]\n",
    "\n",
    "data = []\n",
    "for ws in word_sets:\n",
    "    label, w_set, color, size = ws\n",
    "    x_arr, y_arr = get_x_y_simple(w_set)\n",
    "    data.append(visu.get_trace(label, x_arr, y_arr, w_set, color, size))\n",
    "fig = go.Figure(data=data, layout=visu.get_layout('Word statistics simple','global_val','word_2 frequency'))\n",
    "py.iplot(fig, filename='eval_word_stats_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii.) with rayleigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pos_words = [\"game\",\"play\",\"match\",\"quarter\",\"final\"] + winner_synonyms + loser_synonyms + [\"winner\",\"king\"]\n",
    "neg_words = [\"rolandgarros\",\"frenchopen\",\"clay\",\"slam\",\"set\",\"round\",\"rg17\",\"rolandgarros2017\"] + [\"french\",\"open\",\"rg2017\"]\n",
    "player_words = list(relevant_df[\"key_word\"])\n",
    "\n",
    "word_sets = [\n",
    "    (\"players\", player_words, \"blue\", 5),\n",
    "    (\"positive relevance\", pos_words, \"green\", 10),\n",
    "    (\"negative relevance\", neg_words, \"red\", 10)\n",
    "]\n",
    "\n",
    "data = []\n",
    "for ws in word_sets:\n",
    "    label, w_set, color, size = ws\n",
    "    x_arr, y_arr = get_x_y_ray(w_set)\n",
    "    data.append(visu.get_trace(label, x_arr, y_arr, w_set, color, size))\n",
    "fig = go.Figure(data=data, layout=visu.get_layout('Word statistics with rayleigh','global_val','ray(normalized word_2 frequency)'))\n",
    "py.iplot(fig, filename='eval_word_stats_ray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All word statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. ) without rayleigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pos_neg_words = list(np.union1d(pos_words, neg_words))\n",
    "relevant_words = np.union1d(pos_neg_words, player_words)\n",
    "irrelevant_words = list(set(word_2_counts.index).difference(set(relevant_words)))\n",
    "\n",
    "word_sets = [\n",
    "    (\"irrelevant\", irrelevant_words, \"yellow\", 5),\n",
    "    (\"pos-neg\", pos_neg_words, \"green\", 10),\n",
    "    (\"players\", player_words, \"blue\", 7)\n",
    "]\n",
    "\n",
    "data = []\n",
    "for ws in word_sets:\n",
    "    label, w_set, color, size = ws\n",
    "    x_arr, y_arr = get_x_y_simple(w_set)\n",
    "    data.append(visu.get_trace(label, x_arr, y_arr, w_set, color, size))\n",
    "fig = go.Figure(data=data, layout=visu.get_layout('Word statistics simple','global_val','word_2 frequency'))\n",
    "py.iplot(fig, filename='all_word_stats_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii.) with rayleigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pos_neg_words = list(np.union1d(pos_words, neg_words))\n",
    "relevant_words = np.union1d(pos_neg_words, player_words)\n",
    "irrelevant_words = list(set(word_2_counts.index).difference(set(relevant_words)))\n",
    "\n",
    "word_sets = [\n",
    "    (\"irrelevant\", irrelevant_words, \"yellow\", 5),\n",
    "    (\"pos-neg\", pos_neg_words, \"green\", 10),\n",
    "    (\"players\", player_words, \"blue\", 7)\n",
    "]\n",
    "\n",
    "data = []\n",
    "for ws in word_sets:\n",
    "    label, w_set, color, size = ws\n",
    "    x_arr, y_arr = get_x_y_ray(w_set)\n",
    "    data.append(visu.get_trace(label, x_arr, y_arr, w_set, color, size))\n",
    "fig = go.Figure(data=data, layout=visu.get_layout('Word statistics with rayleigh','global_val','ray(normalized word_2 frequency)'))\n",
    "py.iplot(fig, filename='all_word_stats_ray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_models = et.load_w2v_models(\"%s/dim_%i/\" % (w2v_model_dir, ph.get(\"w2v_model_dim\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_w2v_toplist(w2v_models, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Jaccard and Cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_root_folder = ph.get(\"distance_root_folder\")\n",
    "jaccard_distances = et.load_distance_model(\"%s/jaccard.dist\" % distance_root_folder)\n",
    "cosine_distances = et.load_distance_model(\"%s/cosine.dist\" % distance_root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_distance_toplist(jaccard_distances, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.get_distance_toplist(cosine_distances, [\"nadal\"], [\"2017-06-11T10:00\"], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_map = {\"alma\":1.0,\"korte\":2.0,\"valami\":-5.0}\n",
    "print(et.get_relevance_order(relevant_map))\n",
    "print(et.ndcg(relevant_map, [\"szilva\",\"alma\"], k=1))\n",
    "print(et.ndcg(relevant_map, [\"alma\",\"korte\"], k=1))\n",
    "print(et.ndcg(relevant_map, [\"korte\",\"alma\"], k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ndcg_for_relevant_record(rel_rec, score_col, exclude_player_words=True, top_k=None, general_words=None, verbose=False):\n",
    "    \"\"\"'general_words' must be a relevance dictionary.\"\"\"\n",
    "    time_id, key_word = rel_rec[\"time\"], rel_rec[\"key_word\"]\n",
    "    snapshot_id = \"%sT%s\" % (rel_rec[\"date\"], time_id)\n",
    "    # define relevant words\n",
    "    relevant_words = dict()\n",
    "    relevant_words.update(rel_rec[\"key_relevant_words\"])\n",
    "    relevant_words.update(rel_rec[\"opp_relevant_words\"])\n",
    "    relevant_words.update(rel_rec[\"other_player_relevant\"])\n",
    "    if general_words != None:\n",
    "        relevant_words.update(general_words)\n",
    "    # define words to be excluded from the toplist    \n",
    "    if exclude_player_words:\n",
    "        to_be_excluded = rel_rec[\"key_exclude_words\"]\n",
    "    else:\n",
    "        to_be_excluded = None\n",
    "    # get toplist\n",
    "    if score_col == \"word_2_vec\":\n",
    "        pred_words = list(et.get_w2v_toplist(w2v_models, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded)[\"word_2\"])\n",
    "    elif score_col == \"jaccard\":\n",
    "        pred_words = list(et.get_distance_toplist(jaccard_distances, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded )[\"word_2\"])\n",
    "    elif score_col == \"cosine\":\n",
    "        pred_words = list(et.get_distance_toplist(cosine_distances, [key_word], [snapshot_id], top_k=top_k, excluded_words=to_be_excluded )[\"word_2\"])\n",
    "    else:\n",
    "        pred_words = list(et.get_toplist(pair_occs_df, [key_word], [snapshot_id], score_col=score_col, excluded_words=to_be_excluded)[\"word_2\"])\n",
    "    if verbose:\n",
    "        print(pred_words)\n",
    "        print(relevant_words)\n",
    "    ndcg_score = et.ndcg(relevant_words, pred_words, k=top_k)\n",
    "    return (snapshot_id, rel_rec[\"date\"], time_id, score_col, key_word, ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing, functools\n",
    "\n",
    "def get_ndcg_single_thread(top_k, row, general_words, score_col):\n",
    "    return get_ndcg_for_relevant_record(row, score_col, top_k=top_k, general_words=general_words)\n",
    "\n",
    "def get_ndcg_from_threads(top_k, time_ids, score_cols, general_words, n_threads=1):\n",
    "    print(len(relevant_df))\n",
    "    filtered_relevant_df = relevant_df[relevant_df[\"time\"].isin(time_ids)]\n",
    "    print(len(filtered_relevant_df))\n",
    "    ndcg_info_list = []\n",
    "    if n_threads > 1:\n",
    "        print(\"Calculating NDCG on %i threads\" % n_threads)\n",
    "    for idx, row in filtered_relevant_df.iterrows():\n",
    "        if n_threads == 1:\n",
    "            for score_col in score_cols:\n",
    "                ndcg_info_list += [get_ndcg_single_thread(top_k, row, general_words, score_col)]\n",
    "        else:\n",
    "            f_partial = functools.partial(get_ndcg_single_thread, top_k, row, general_words)\n",
    "            pool = multiprocessing.Pool(processes=n_threads)\n",
    "            res = pool.map(f_partial, score_cols)\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            ndcg_info_list += res\n",
    "    ndcg_df = pd.DataFrame(ndcg_info_list, columns=[\"snapshot_id\",\"date\",\"time\",\"score_id\",\"key_word\",\"ndcg\"])\n",
    "    return ndcg_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting general words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#score = \"rel_count_c2\"\n",
    "score = \"norm_c2\"\n",
    "et.get_toplist(pair_occs_df, [\"timea\"], [\"2017-06-08T07:00\"], score_col=score).head(20)[[\"word_1\",\"word_2\",score]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "score = \"norm_c5\"\n",
    "et.get_toplist(pair_occs_df, [\"wawrinka\"], [\"2017-06-11T13:00\"], score_col=score).head(20)[[\"word_1\",\"word_2\",score]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "et.get_distance_toplist(cosine_distances, [\"wawrinka\"], [\"2017-06-11T13:00\"], top_k=20).head(20)[[\"word_1\",\"word_2\",\"distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general_words = {\n",
    "    \"game\":MATCH_INFO_RELEVANCE,\n",
    "    \"play\":MATCH_INFO_RELEVANCE, \n",
    "    \"match\":MATCH_INFO_RELEVANCE,\n",
    "}\n",
    "if RELEVANCE_SUBSET == \"discriminative\":\n",
    "    general_words.update({\n",
    "        \"rg17\":COMMON_WORD_RELEVANCE,\n",
    "        \"rg2017\":COMMON_WORD_RELEVANCE,\n",
    "        \"rolandgarros\":COMMON_WORD_RELEVANCE,\n",
    "        \"roland\":COMMON_WORD_RELEVANCE,\n",
    "        \"garros\":COMMON_WORD_RELEVANCE,\n",
    "        \"rolandgarros2017\":COMMON_WORD_RELEVANCE,\n",
    "        \"frenchopen\":COMMON_WORD_RELEVANCE,\n",
    "        \"french\":COMMON_WORD_RELEVANCE,\n",
    "        \"open\":COMMON_WORD_RELEVANCE,\n",
    "        \"clay\":COMMON_WORD_RELEVANCE,\n",
    "        \"slam\":COMMON_WORD_RELEVANCE,\n",
    "        \"set\":COMMON_WORD_RELEVANCE,\n",
    "        \"round\":COMMON_WORD_RELEVANCE      \n",
    "    })\n",
    "print(general_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cols = [\"word_2_vec\", \"jaccard\", \"cosine\"]\n",
    "#score_cols += [\"rel_count_c%i_plus_ray\" % i for i in [0,1,2,5,10]]\n",
    "#score_cols += [\"norm_c%i_plus_ray\" % i for i in [0,1,2,5,10]]\n",
    "score_cols += [\"rel_count_c%i\" % i for i in score_vals]\n",
    "score_cols += [\"norm_c%i\" % i for i in score_vals]\n",
    "print(score_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting time of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time_ids = [\"%.2i:00\" % t for t in TIME_HOUR_VALS]\n",
    "time_ids = [\"%.2i:00\" % t for t in [4,7,10,13,16,19]]\n",
    "time_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDCG in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ndcg_df = get_ndcg_from_threads(20, time_ids, score_cols, general_words, n_threads=4)#len(time_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ndcg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean NDCG performance for score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ndcg_df.groupby(by=\"score_id\")[\"ndcg\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndcg_for_plots = ndcg_df[ndcg_df[\"score_id\"].isin([\"word_2_vec\",\"cosine\",\"jaccard\",\"rel_count_c5\",\"norm_c5\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_rc = {'lines.linewidth': 5,'lines.markersize': 20}              \n",
    "sns.set_context(\"paper\", rc = paper_rc, font_scale = 4.25)\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#sns.set(font=\"DejaVu Sans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) Compare co-occurence scores for snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "g = sns.factorplot(data=ndcg_for_plots, x=\"snapshot_id\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.) Compare co-occurence scores for date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(data=ndcg_for_plots, x=\"date\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii.)  Compare co-occurence scores for time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=ndcg_for_plots, x=\"time\", y=\"ndcg\", hue=\"score_id\", size=10, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv.) Difference between players keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_player_perf(key_words):\n",
    "    score_filtered = ndcg_for_plots[ndcg_for_plots[\"key_word\"].isin(key_words)]\n",
    "    score_filtered = score_filtered[score_filtered[\"score_id\"] == \"rel_count_c5\"]\n",
    "    score_filtered = score_filtered[score_filtered[\"date\"].isin([\"2017-06-08\",\"2017-06-09\",\"2017-06-10\",\"2017-06-11\"])]\n",
    "    g = sns.factorplot(data=score_filtered, x=\"snapshot_id\", y=\"ndcg\", hue=\"key_word\", size=10, aspect=3)\n",
    "    g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_names = [\"nadal\",\"wawrinka\",\"ostapenko\",\"halep\",\"murray\",\"djokovic\",\"cilic\",\"thiem\",\"pliskova\",\"bacsinszky\"]\n",
    "first_names = [\"rafael\",\"stan\",\"jelena\",\"simona\",\"andy\",\"novak\",\"marin\",\"dominic\",\"karolina\",\"timea\"]\n",
    "account_names = [\"@RafaelNadal\",\"@stanwawrinka\",\"@OstapenkoFC\",\"@Simona_Halep\",\"@andy_murray\",\"@DjokerNole\", \"@cilic_marin\", \"@ThiemDomi\", \"@KaPliskova\", \"@TimeaOfficial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_player_perf(last_names)\n",
    "show_player_perf(first_names)\n",
    "show_player_perf(account_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}