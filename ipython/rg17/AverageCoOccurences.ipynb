{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font=\"DejaVu Sans\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from rg17 import evaluate_toplist as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../pipelines/TrendApproximation.json\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_id = ph.get(\"experiment_id\")\n",
    "shedule_file_path = ph.get(\"schedule_file_path\")\n",
    "screen_names_file_path = ph.get(\"player_screen_names_file_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load player accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_accounts = et.load_player_accounts(screen_names_file_path, remove_digits=False, remove_under_score=False, to_lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_accounts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load occurances file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd = pd.read_csv(\"/mnt/idms/fberes/network/combined_occ/occ_tables/%s.csv\" % experiment_id, sep=\"|\")\n",
    "len(occurences_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping irrelevant snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd[\"date\"] = occurences_pd[\"start_time\"].apply(lambda x: x.split(\"T\")[0])\n",
    "occurences_pd = occurences_pd[~occurences_pd[\"date\"].isin(['2017-06-12','2017-06-13','2017-06-14','2017-06-15','2017-06-16'])]\n",
    "len(occurences_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: lot of missing players? duplications?\n",
    "\n",
    "#### Simona Halep\n",
    "   * @Simona_Halep kor\u00e1bban nem volt el\u0151fordul\u00e1sa - most m\u00e1r van\n",
    "   * de @simonahalep-nak tov\u00e1bbra is vannak..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(player_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(occurences_pd[\"key_word\"].unique()).intersection(set(player_accounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(player_accounts).difference(set(occurences_pd[\"key_word\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_cols = [str(i) for i in range(1,201,2)]\n",
    "count_cols = [str(i) for i in range(2,201,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional words to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "special_words = []\n",
    "special_words += [\"rolandgarros\", \"frenchopen\"]\n",
    "special_words += [\"match\", \"play\", \"fight\", \"face\", \"result\", \"court\", \"now\", \"today\", \"tomorrow\", \"injury\", \"shock\"]\n",
    "special_words += [\"qualifi\", \"surviv\", \"elimin\", \"domin\"]\n",
    "special_words += [\"birthday\"]\n",
    "special_words += [\"wins\", \"win\", \"won\", \"champion\", \"champ\", \"king\", \"beat\", \"trophy\", \"triumph\", \"overcom\"]\n",
    "special_words += [\"lose\", \"loss\", \"lost\", \"defeat\", \"beaten\", \"broken\", \"break\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men, Women Finalists in Single tournaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "special_words += [\"rafa\",\"nadal\",\"rafael\",\"rafaelnadal\"]\n",
    "special_words += [\"stan\",\"wawrinka\",\"stantheman\"]\n",
    "special_words += [\"andy\",\"murray\",\"andymurray\"]\n",
    "special_words += [\"thiem\",\"dominic\"]\n",
    "special_words += [\"novak\",\"djokovic\"]\n",
    "special_words += ['svitolina', 'elina']\n",
    "special_words += ['carreno', 'busta', 'pablo']\n",
    "special_words += ['timea', 'bacsinszky']\n",
    "special_words += ['jelena', 'ostapenko']\n",
    "special_words += ['halep', 'simona']\n",
    "special_words += ['karolina', 'pliskova']\n",
    "special_words += ['mladenovic', 'kristina']\n",
    "special_words += ['caroline', 'wozniacki']\n",
    "special_words += ['caroline', 'garcia']\n",
    "special_words += ['nishikori', 'kei']\n",
    "special_words += ['cilic', 'marin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occurences_pd = occurences_pd[occurences_pd[\"key_word\"].isin(player_accounts+special_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(occurences_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restructure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rel_count_with_offset(counts, kw_count, c):\n",
    "    return (c + np.array(counts)) / (c + kw_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: use float column names rather!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_const_list = [0.001,1.0,2.0,5.0,10.0]\n",
    "rel_count_cols = [\"rel_count_%i\" % c for c in c_const_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pd.DataFrame()\n",
    "size = len(word_cols)\n",
    "for idx, row in occurences_pd.iterrows():\n",
    "    start_time, key_word, key_word_count = row[\"start_time\"], row[\"key_word\"], row[\"count\"]\n",
    "    hour = start_time.split(\"T\")[1][:2]\n",
    "    hours, times, key_words = zip(*((hour,start_time,key_word) for i in range(size)))\n",
    "    values = [times,hours,key_words,row[word_cols]] + [get_rel_count_with_offset(row[count_cols], key_word_count, c) for c in c_const_list]\n",
    "    cols = [\"time\",\"hour\",\"word_1\",\"word_2\"] + rel_count_cols\n",
    "    some_occs = list(zip(*values))\n",
    "    tmp_df = pd.DataFrame(some_occs, columns=cols)\n",
    "    # exclude no hits\n",
    "    tmp_df = tmp_df[~tmp_df[\"word_2\"].isnull()]\n",
    "    # exclude self occurences\n",
    "    tmp_df = tmp_df[tmp_df[\"word_2\"] != key_word]\n",
    "    pair_occs_df = pd.concat([pair_occs_df, tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pair_occs_df.reset_index()\n",
    "del pair_occs_df[\"index\"]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop words that did not occur in more than 2 snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2_freqs = pair_occs_df.groupby(by=[\"word_2\"])[\"time\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2_freqs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(word2_freqs > 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_word_2 = list(word2_freqs[word2_freqs > 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2_freqs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pair_occs_df[pair_occs_df[\"word_2\"].isin(filtered_word_2)]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Dropping excluded words: @rolandgarros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pair_occs_df[~pair_occs_df[\"word_2\"].isin([\"@rolandgarros\"])]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate co-occurence statistics for snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't want include the last day into statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"date\"] = pair_occs_df[\"time\"].apply(lambda x: x.split(\"T\")[0])\n",
    "pair_occs_for_stats_df = pair_occs_df[~pair_occs_df[\"date\"].isin(['2017-06-11'])]\n",
    "print(len(pair_occs_for_stats_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Actually I should compute the occ_scores temporally (only taking into account the past occurences...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Calculate global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_count_occs = pair_occs_for_stats_df.groupby(by=[\"word_1\",\"word_2\"])[rel_count_cols[0]].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop occurences that occur in only one snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(global_count_occs))\n",
    "count_tmp_df = global_count_occs[global_count_occs[rel_count_cols[0]] > 1]\n",
    "print(len(count_tmp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_word_pairs = set(zip(count_tmp_df[\"word_1\"],count_tmp_df[\"word_2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_pair_occs_df = pair_occs_for_stats_df[pair_occs_for_stats_df.apply(lambda x: (x[\"word_1\"], x[\"word_2\"]) in filtered_word_pairs, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(filtered_pair_occs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mean of the fractions for all snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_mean_occs = filtered_pair_occs_df.groupby(by=[\"word_1\",\"word_2\"])[rel_count_cols].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(global_mean_occs) == len(count_tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_occs[rel_count_cols].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_occs[\"key\"] = list(zip(global_mean_occs[\"word_1\"],global_mean_occs[\"word_2\"]))\n",
    "GLOBAL_MEANS = global_mean_occs[rel_count_cols+[\"key\"]].set_index(\"key\").T.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "GLOBAL_MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Calculate snapshot mean\n",
    "\n",
    "#### Still using only (word1,word2) pairs that occured in multiple snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot_mean_occs = filtered_pair_occs_df.groupby(by=[\"word_1\",\"word_2\",\"hour\"])[rel_count_cols].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot_mean_occs[\"key\"] = list(zip(snapshot_mean_occs[\"word_1\"],snapshot_mean_occs[\"word_2\"],snapshot_mean_occs[\"hour\"]))\n",
    "SNAPSHOT_MEANS = snapshot_mean_occs[rel_count_cols+[\"key\"]].set_index(\"key\").T.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNAPSHOT_MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate occurence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_with_global_score(row):\n",
    "    key = (row[\"word_1\"],row[\"word_2\"])\n",
    "    return GLOBAL_MEANS[key] if key in GLOBAL_MEANS else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"global_val\"] = pair_occs_df.apply(fill_with_global_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_with_snapshot_score(row):\n",
    "    key = (row[\"word_1\"],row[\"word_2\"],row[\"hour\"])\n",
    "    return SNAPSHOT_MEANS[key] if key in SNAPSHOT_MEANS else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"snapshot_val\"] = pair_occs_df.apply(fill_with_snapshot_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df.to_csv(\"/mnt/idms/fberes/network/combined_occ/occ_scores/%s_with_scores.csv\" % experiment_id, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_norm_score(row, c_val, alpha=0, eps=0.0):\n",
    "    val_key = \"rel_count_%i\" % c_val\n",
    "    global_norm = row[\"global_val\"][val_key] if row[\"global_val\"] != 0 else 0\n",
    "    snapshot_norm = row[\"snapshot_val\"][val_key] if row[\"snapshot_val\"] != 0 else 0\n",
    "    # both normalization constant is missing\n",
    "    if global_norm == 0 and snapshot_norm == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (eps + (2.0 + alpha) * row[val_key]) / (eps + global_norm + snapshot_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_val, alpha_val = 1, 0\n",
    "pair_occs_df[\"norm_c%i_a%i\" % (c_val, alpha_val)] = pair_occs_df.apply(lambda x: calculate_norm_score(x,c_val=1, alpha=alpha_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"day\"] = pair_occs_df[\"time\"].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_score(w1, w2, score_name=\"norm_c1_a0\"):\n",
    "    filtered_df = pair_occs_df[(pair_occs_df[\"word_1\"] == w1) & (pair_occs_df[\"word_2\"] == w2)]\n",
    "    pivot_scores = pd.pivot_table(filtered_df, values=score_name, index=\"hour\", columns=\"day\")\n",
    "    fig, ax = plt.subplots(figsize=(30,5))\n",
    "    plt.title(\"%s->%s: %i record\" % (w1, w2, len(filtered_df)))\n",
    "    sns.heatmap(pivot_scores, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schedule_df = pd.read_csv(shedule_file_path, sep=\"|\")\n",
    "schedule_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rafa nadal matches\n",
    "\n",
    "   * the first few matches of Nadal has high scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"Rafael Nadal\"\n",
    "schedule_df[(schedule_df[\"playerName active\"] == name) | (schedule_df[\"playerName opponent\"] == name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@RafaelNadal\",\"match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@RafaelNadal\",\"win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are the two finalist mentioned together (Men's single final on 06-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@RafaelNadal\",\"@stanwawrinka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The winner is Nadal (Men's single final on 06-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@RafaelNadal\",\"champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@stanwawrinka\",\"champion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loser is Wawrinka (Men's single final on 06-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@stanwawrinka\",\"beat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@RafaelNadal\",\"beat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadal birthday: June 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@RafaelNadal\",\"birthday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novak Djokovic lost on 06-07 - occurences score diminishes after this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"Novak Djokovic\"\n",
    "schedule_df[(schedule_df[\"playerName active\"] == name) | (schedule_df[\"playerName opponent\"] == name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_score(\"@DjokerNole\",\"match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Toplists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_toplist(w1, snapshot_id, score_name=\"norm_c1_a0\"):\n",
    "    filtered_df = pair_occs_df[(pair_occs_df[\"word_1\"] == w1) & (pair_occs_df[\"time\"] == snapshot_id)]\n",
    "    return filtered_df.sort_values(score_name, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"@stanwawrinka\" and \"final\" is in top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T07:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@rafaelnadal\",\"2017-06-10T18:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"@stanwawrinka\" is in top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T10:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"win\", \"title\" and \"champion\" is in top words + \"congrat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T13:00\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T16:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nadal birthday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-03T16:00\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pair_occs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_toplist(\"play\",\"2017-06-04T16:00\").head(20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}