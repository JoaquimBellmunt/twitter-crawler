{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_file = \"/mnt/idms/fberes/network/online_ranker/roland_garros_updated_schedule/recoded_player_accounts.txt\"\n",
    "player_accounts = []\n",
    "with open(player_file) as f:\n",
    "    for line in f:\n",
    "        player_accounts.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(player_accounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_text = pd.read_csv(\"/mnt/idms/fberes/network/roland_garros/data/rg17_tweets_eng.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_text[\"date\"] = pd.to_datetime(tweets_with_text[\"time\"],unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_text[\"date_id\"] = tweets_with_text[\"date\"].apply(lambda x: str(x)[:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_text[\"date_id\"].value_counts()[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify text before groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_with_text[\"text\"] = tweets_with_text[\"text\"].apply(lambda x: \" \" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_docs = tweets_with_text.groupby(\"date_id\")[\"text\"].apply(lambda x: x.sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_docs = grouped_docs.drop(0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(t):\n",
    "    clean_1 = ' '.join(re.findall(\"[\\w,\\@]+\",t))\n",
    "    clean_2 = ' '.join(re.findall(\"[^\\,,\\d]+\",clean_1))\n",
    "    return clean_2.lower()\n",
    "\n",
    "def get_words(t, size_limit):\n",
    "    words = []\n",
    "    for w in t.split(\" \"):\n",
    "        if len(w) > size_limit:\n",
    "            words.append(w)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_docs[\"text_clean\"] = grouped_docs[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_docs[\"text_clean\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_docs[\"words\"] = grouped_docs[\"text_clean\"].apply(lambda x: get_words(x,2))\n",
    "grouped_docs[\"num_words\"] = grouped_docs[\"words\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = set([])\n",
    "for idx, row in grouped_docs.iterrows():\n",
    "    all_words = all_words.union(set(row[\"words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tweet text representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_representations = []\n",
    "for idx, row in grouped_docs.iterrows():\n",
    "    cnt = Counter(row[\"words\"])\n",
    "    cnt_repr = dict(zip(all_words,np.zeros(len(all_words))))\n",
    "    cnt_repr.update(dict(cnt))\n",
    "    word_representations.append(cnt_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(word_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_arr = word_counts.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_arr = transformer.fit_transform(word_counts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ids_df = pd.DataFrame(tfidf_arr.todense(), columns=list(word_counts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ids_df = tf_ids_df.replace(to_replace=0, value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ids_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping stop words\n",
    "\n",
    "http://www.ranks.nl/stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open(\"stop_words_en_long.txt\") as f:\n",
    "    for line in f:\n",
    "        stop_words.append(line.rstrip())\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words_intersection = []\n",
    "for sw in stop_words:\n",
    "    if sw in tf_ids_df.columns:\n",
    "        stop_words_intersection.append(sw)\n",
    "len(stop_words_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_ids_df = tf_ids_df.drop(stop_words_intersection,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_tf_idf = tf_ids_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_tf_idf = sum_tf_idf.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_tf_idfs = sum_tf_idf[sum_tf_idf.index.isin(player_accounts)]\n",
    "non_player_tf_idfs = sum_tf_idf[~sum_tf_idf.index.isin(player_accounts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "sum_tf_idf.hist(bins=100)\n",
    "plt.subplot(1,2,2)\n",
    "player_tf_idfs.hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(non_player_tf_idfs.index[i],non_player_tf_idfs.ix[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make final list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_player_words = list(non_player_tf_idfs.head(top).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = non_player_words + player_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First 3-6 words should be eliminated:**\n",
    "    * @rolandgarros\n",
    "    * amp\n",
    "**Should I delete these frequent words?**\n",
    "    * rolandgarros\n",
    "    * tennis\n",
    "    * french\n",
    "    * open\n",
    "    * day\n",
    "    * roland?\n",
    "    * garros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_words = [\"@rolandgarros\",\"amp\"]#,\"frenchopen\",\"rolandgarros\",\"tennis\",\"french\",\"open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in excluded_words:\n",
    "    all_words.remove(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/mnt/idms/fberes/network/roland_garros/data/rg17_%i_important_en_words_plus_players.txt\" % top, 'w') as f_out:\n",
    "    for w in all_words:\n",
    "        f_out.write(\"%s\\n\" % w)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}