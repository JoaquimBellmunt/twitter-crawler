{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"../python/\")\n",
    "import analyzer_utils as au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coll_name = \"grenfell_fire\"\n",
    "coll, db = au.get_coll(coll_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of documents in the collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coll_size = db.command(\"collstats\", coll_name)[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of docs in '%s': %i\" % (coll_name, coll_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = coll.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper and lower bound of the available dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "au.find_some_docs(coll,sort_params=[(\"id\",1)],limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au.find_some_docs(coll,limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hashtags_from_tweets(coll,limit=None):\n",
    "    res = coll.find().limit(limit) if limit != None else coll.find()\n",
    "    hashtags = {}\n",
    "    for item in res:\n",
    "        if \"RT \" == item['text'][:3]:\n",
    "            continue\n",
    "        for htag in item['entities']['hashtags']:\n",
    "            htag_name = htag['text']\n",
    "            if not htag_name in hashtags:\n",
    "                hashtags[htag_name] = 0\n",
    "            hashtags[htag_name] += 1\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = get_hashtags_from_tweets(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc = Counter(hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract mention networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Extract mentions from multiple collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions, user_names, num_tweets, num_retweets = au.get_mentions(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions_df = pd.DataFrame(mentions,columns=[\"epoch\",\"src\",\"trg\",\"text\"])\n",
    "print(len(mentions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentions_df[\"src_str\"] =  mentions_df[\"src\"].apply(lambda x: user_names[x])\n",
    "mentions_df[\"trg_str\"] =  mentions_df[\"trg\"].apply(lambda x: user_names[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Number of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of tweets: %i\" % num_tweets)\n",
    "print(\"Number of retweets: %i\" % num_retweets)\n",
    "print(\"Number of mentions extracted from tweets: %i\" % len(mentions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export mentions to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_export = [\"epoch\",\"src\",\"trg\",\"src_str\",\"trg_str\"]\n",
    "mentions_df.to_csv(\"/mnt/idms/fberes/network/grenfell_fire//data/gff17_mentions.csv\",columns=cols_to_export,sep=\"|\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions_df = pd.read_csv(\"/mnt/idms/fberes/network/grenfell_fire/data/gff17_mentions.csv\",sep=\"|\")\n",
    "mentions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_map = dict(zip(mentions_df[\"src\"],mentions_df[\"src_str\"]))\n",
    "trg_map = dict(zip(mentions_df[\"trg\"],mentions_df[\"trg_str\"]))\n",
    "src_map.update(trg_map)\n",
    "user_names = src_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Popular source nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "au.show_frequent_items(mentions_df,user_names,\"src\",k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Popular target nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "au.show_frequent_items(mentions_df,user_names,\"trg\",k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Event distribution in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mentions_df[\"date\"] = mentions_df[\"epoch\"].apply(lambda x: time.strftime('%Y-%m-%d', time.localtime(x)))\n",
    "mentions_df[\"date\"] = mentions_df[\"epoch\"].apply(lambda x: time.strftime('%Y-%m-%d %H', time.localtime(x)))\n",
    "mentions_df[\"time\"] = mentions_df[\"epoch\"].apply(lambda x: time.strftime('%H:%M:%S', time.localtime(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title(\"Number of mentions in time\")\n",
    "mentions_df[\"epoch\"].hist(bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_of_mentions_by_day = mentions_df[\"date\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title(\"Number of mentions per day\")\n",
    "plt.plot(num_of_mentions_by_day.values)\n",
    "plt.xticks(range(len(num_of_mentions_by_day)),num_of_mentions_by_day.index,rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Graph informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_splits = sorted(list(mentions_df[\"date\"].unique()))\n",
    "#date_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_stats = [] \n",
    "for split in date_splits[1:]:\n",
    "    partial_df = mentions_df[mentions_df[\"date\"] < split]\n",
    "    graph_stats += [au.get_graph_stats(partial_df)]\n",
    "graph_stats_df = pd.DataFrame(graph_stats, columns=[\"nodes\",\"edges\",\"weak_components\",\"strong_components\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_stats_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Aggregated mention graph size')\n",
    "plt.plot(graph_stats_df[\"nodes\"],label=\"nodes\")\n",
    "plt.plot(graph_stats_df[\"edges\"],label=\"edges\")\n",
    "plt.xticks(range(len(graph_stats_df)),date_splits[:-1],rotation='vertical')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Number of weak components in the aggregated mention graph')\n",
    "plt.plot(graph_stats_df[\"weak_components\"],label=\"number of \",c=\"r\")\n",
    "plt.xticks(range(len(graph_stats_df)),date_splits[:-1],rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}